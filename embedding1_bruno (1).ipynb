{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#importar datasets de proves y splitter alemany\n",
        "!pip install datasets evaluate --upgrade\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "id": "tOmiCUUjxBRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1682651-08d8-4080-d77f-c980fe103c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import spacy\n",
        "import datasets\n",
        "import torchtext\n",
        "import tqdm\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "VOcysd8F9E-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creem un dataset a partir del txt que serà un diccionari amb les claus dels idiomes (en i de) i com a valor una llista de les frases traduïdes en ordre"
      ],
      "metadata": {
        "id": "ICBU0pmu0TND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_ccby(linea):\n",
        "    indice_ccby = linea.find(\"CC-BY\")\n",
        "    if indice_ccby != -1:\n",
        "        return linea[:indice_ccby]\n",
        "    return linea\n",
        "\n",
        "def separar_frases(linea):\n",
        "    patron = r'(.+?[.!?])\\s+([^A-Z]?[\\s]+)?(.+)?'\n",
        "    coincidencias = re.match(patron, linea)\n",
        "    if coincidencias:\n",
        "        frase1 = coincidencias.group(1)\n",
        "        frase2 = coincidencias.group(3)\n",
        "        return frase1.strip(), frase2.strip() if frase2 else None\n",
        "    else:\n",
        "        return None, None\n",
        "\n",
        "def make_dataset(archivo_entrada):\n",
        "    dataset = []\n",
        "    with open(archivo_entrada, 'r') as f_in:\n",
        "        for linea in f_in:\n",
        "            linea_clean = eliminar_ccby(linea)\n",
        "            a,b = separar_frases(linea_clean)\n",
        "            dataset.append({'en':a,'de':b})\n",
        "    return dataset\n",
        "\n",
        "archivo_entrada = 'deu.txt'\n",
        "data = make_dataset(archivo_entrada)"
      ],
      "metadata": {
        "id": "PW4EWTTG65qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:10])"
      ],
      "metadata": {
        "id": "5dRQzJPn8Kaq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a09d65-20e8-4d0b-80e8-dbe1ddb71ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'en': 'Go.', 'de': 'Geh.'}, {'en': 'Hi.', 'de': 'Hallo!'}, {'en': 'Hi.', 'de': 'Grüß Gott!'}, {'en': 'Run!', 'de': 'Lauf!'}, {'en': 'Run.', 'de': 'Lauf!'}, {'en': 'Wow!', 'de': 'Potzdonner!'}, {'en': 'Wow!', 'de': 'Donnerwetter!'}, {'en': 'Duck!', 'de': 'Kopf runter!'}, {'en': 'Fire!', 'de': 'Feuer!'}, {'en': 'Help!', 'de': 'Hilfe!'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importem splitters d'anglés i alemany"
      ],
      "metadata": {
        "id": "aOzfAoo-xpm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "en_nlp = spacy.load(\"en_core_web_sm\")\n",
        "de_nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "4NG1erfVwnb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"What a lovely day it is today!\"\n",
        "[token.text for token in en_nlp.tokenizer(string)]"
      ],
      "metadata": {
        "id": "PFAcsPsLwcxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64457c78-535a-422c-c536-71dfa04adc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada par de oraciones añadimos a más su split correspondiente con el incio y fin de frase y tenemos en cuenta las mayúsculas"
      ],
      "metadata": {
        "id": "euRXNXOJ9LVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_example(data, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
        "    for i in range(len(data)):\n",
        "        en_tokens = [token.text for token in en_nlp.tokenizer(data[i][\"en\"])][:max_length]\n",
        "        de_tokens = [token.text for token in de_nlp.tokenizer(data[i][\"de\"])][:max_length]\n",
        "        if lower:\n",
        "            en_tokens = [token.lower() for token in en_tokens]\n",
        "            de_tokens = [token.lower() for token in de_tokens]\n",
        "        en_tokens = [sos_token] + en_tokens + [eos_token]\n",
        "        de_tokens = [sos_token] + de_tokens + [eos_token]\n",
        "        data[i]['en_tokens'] = en_tokens\n",
        "        data[i]['de_tokens'] = de_tokens\n",
        "    return data"
      ],
      "metadata": {
        "id": "8fYTwoF1wdfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data[:1000]\n",
        "max_length = 1000\n",
        "lower = True\n",
        "sos_token = \"<sos>\"\n",
        "eos_token = \"<eos>\"\n",
        "\n",
        "fn_kwargs = {\n",
        "    \"example\": train,\n",
        "    \"en_nlp\": en_nlp,\n",
        "    \"de_nlp\": de_nlp,\n",
        "    \"max_length\": max_length,\n",
        "    \"lower\": lower,\n",
        "    \"sos_token\": sos_token,\n",
        "    \"eos_token\": eos_token,\n",
        "}\n",
        "inputs = [train,en_nlp,de_nlp,max_length,lower,sos_token,eos_token]"
      ],
      "metadata": {
        "id": "FJCMkpMvxir1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sos = start of sentence,\n",
        "eos = end of sentence,\n",
        "unk = unknown,\n",
        "pad = padding"
      ],
      "metadata": {
        "id": "tnqDC5cvHj0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = tokenize_example(*inputs)\n",
        "train[0]"
      ],
      "metadata": {
        "id": "SAt1W-jM2Ijb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e47cf9a-0ad5-43c8-845b-f1cfeb924654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'Go.',\n",
              " 'de': 'Geh.',\n",
              " 'en_tokens': ['<sos>', 'go', '.', '<eos>'],\n",
              " 'de_tokens': ['<sos>', 'geh', '.', '<eos>']}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_freq = 2\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "\n",
        "special_tokens = [\n",
        "    unk_token,\n",
        "    pad_token,\n",
        "    sos_token,\n",
        "    eos_token,\n",
        "]\n",
        "\n",
        "\n",
        "all_en_tokens, all_de_tokens = [], []\n",
        "for frase in train:\n",
        "    all_en_tokens.append(frase['en_tokens'])\n",
        "    all_de_tokens.append(frase['de_tokens'])\n",
        "\n",
        "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "    all_en_tokens,\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")\n",
        "\n",
        "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
        "    all_de_tokens,\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")"
      ],
      "metadata": {
        "id": "ycngKIHS7rNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_en, words_de = en_vocab.get_itos(), de_vocab.get_itos()\n",
        "len(words_en), len(words_de)"
      ],
      "metadata": {
        "id": "SnoNuCn1B5ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d8a2b4-859d-4026-dcb3-160738cef3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(262, 297)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
        "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
        "\n",
        "unk_index = en_vocab[unk_token]\n",
        "pad_index = en_vocab[pad_token]\n",
        "\n",
        "en_vocab.set_default_index(unk_index)\n",
        "de_vocab.set_default_index(unk_index)"
      ],
      "metadata": {
        "id": "0H5fZN9nLDeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"man\" in words_en"
      ],
      "metadata": {
        "id": "Jkhs_WAiG9dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d5463f-0951-4f60-f708-237fa514e8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numericalize_example(data, en_vocab, de_vocab):\n",
        "    for i in range(len(data)):\n",
        "        en_ids = en_vocab.lookup_indices(data[i][\"en_tokens\"])\n",
        "        de_ids = de_vocab.lookup_indices(data[i][\"de_tokens\"])\n",
        "        data[i]['en_ids'] = en_ids\n",
        "        data[i]['de_ids'] = de_ids\n",
        "    return data"
      ],
      "metadata": {
        "id": "moShDoM1HB7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = numericalize_example(train, en_vocab, de_vocab)\n",
        "train[100]"
      ],
      "metadata": {
        "id": "1i6NUrd-JQl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bd1206-bca8-4ae4-d4ed-1669f4579842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'No way!',\n",
              " 'de': 'Das kommt nicht in Frage!',\n",
              " 'en_tokens': ['<sos>', 'no', 'way', '!', '<eos>'],\n",
              " 'de_tokens': ['<sos>', 'das', 'kommt', 'nicht', 'in', 'frage', '!', '<eos>'],\n",
              " 'en_ids': [2, 59, 90, 7, 3],\n",
              " 'de_ids': [2, 16, 71, 21, 43, 0, 5, 3]}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'equivalència token - índex és correcte"
      ],
      "metadata": {
        "id": "Y4C3LyWJNcG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train[100][\"en_tokens\"])\n",
        "print(en_vocab.lookup_tokens(train[100][\"en_ids\"]))\n",
        "train[100][\"en_tokens\"] == en_vocab.lookup_tokens(train[100][\"en_ids\"])"
      ],
      "metadata": {
        "id": "QyJX6UXvJbNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a1060a-aaaa-4207-a2cf-d5a57663b71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<sos>', 'no', 'way', '!', '<eos>']\n",
            "['<sos>', 'no', 'way', '!', '<eos>']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train)):\n",
        "    en_ids = train[i]['en_ids']\n",
        "    de_ids = train[i]['de_ids']\n",
        "    train[i]['en_ids'] = torch.tensor(en_ids)\n",
        "    train[i]['de_ids'] = torch.tensor(de_ids)\n",
        "train[100]"
      ],
      "metadata": {
        "id": "2OTwOZRiNNAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301e3fd1-4895-4fc0-bb92-21c6dbc737dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en': 'No way!',\n",
              " 'de': 'Das kommt nicht in Frage!',\n",
              " 'en_tokens': ['<sos>', 'no', 'way', '!', '<eos>'],\n",
              " 'de_tokens': ['<sos>', 'das', 'kommt', 'nicht', 'in', 'frage', '!', '<eos>'],\n",
              " 'en_ids': tensor([ 2, 59, 90,  7,  3]),\n",
              " 'de_ids': tensor([ 2, 16, 71, 21, 43,  0,  5,  3])}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ara ja tenim el dataset amb totes les des necessàries per començar el entrenament del model"
      ],
      "metadata": {
        "id": "pFgNUx8kgsVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lista_grande = [i*3 for i in range(100)]\n",
        "\n",
        "import h5py\n",
        "\n",
        "# Guardar la lista en un archivo HDF5\n",
        "with h5py.File('datos.h5', 'w') as f:\n",
        "    f.create_dataset('lista', data=lista_grande)\n",
        "\n",
        "# Recuperar la lista del archivo HDF5\n",
        "with h5py.File('datos.h5', 'r') as f:\n",
        "    lista_grande_recuperada = f['lista'][:]\n",
        "\n",
        "\n",
        "lista_grande_recuperada"
      ],
      "metadata": {
        "id": "SzOina2DgjHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948ce462-1a24-4fdd-ab7a-d278e25c16f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   3,   6,   9,  12,  15,  18,  21,  24,  27,  30,  33,  36,\n",
              "        39,  42,  45,  48,  51,  54,  57,  60,  63,  66,  69,  72,  75,\n",
              "        78,  81,  84,  87,  90,  93,  96,  99, 102, 105, 108, 111, 114,\n",
              "       117, 120, 123, 126, 129, 132, 135, 138, 141, 144, 147, 150, 153,\n",
              "       156, 159, 162, 165, 168, 171, 174, 177, 180, 183, 186, 189, 192,\n",
              "       195, 198, 201, 204, 207, 210, 213, 216, 219, 222, 225, 228, 231,\n",
              "       234, 237, 240, 243, 246, 249, 252, 255, 258, 261, 264, 267, 270,\n",
              "       273, 276, 279, 282, 285, 288, 291, 294, 297])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Supongamos que tenemos un vocabulario de tamaño 10 y queremos vectores de embedding de dimensión 5\n",
        "vocab_size = 10\n",
        "embedding_dim = 5\n",
        "\n",
        "# Creamos una capa de embedding con el tamaño de vocabulario y la dimensión del embedding especificados\n",
        "embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
        "\n",
        "# Creamos una secuencia de entrada de índices\n",
        "input_indices = torch.tensor([1, 3, 5, 7, 9])\n",
        "\n",
        "# Pasamos la secuencia de entrada a través de la capa de embedding\n",
        "embedded_vectors = embedding_layer(input_indices)\n",
        "\n",
        "# Mostramos los vectores de embedding resultantes\n",
        "print(\"Vectores de embedding:\")\n",
        "print(embedded_vectors)"
      ],
      "metadata": {
        "id": "xg7GX_bphYVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83dcd590-4d0b-45a0-d561-10bd16ef6533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectores de embedding:\n",
            "tensor([[ 0.3530, -2.1909,  0.5289, -0.8239, -1.4213],\n",
            "        [ 0.3565,  1.1609, -1.1227, -1.1443, -1.5309],\n",
            "        [-0.6661, -1.3697, -1.3740,  0.5193,  0.7109],\n",
            "        [ 0.1386, -0.5379,  0.7494,  0.6972, -0.1818],\n",
            "        [ 1.5970, -1.0652,  0.5939,  0.3656,  1.2412]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creem una classe básica dicionari per crear el dataloader de la llibreria torch"
      ],
      "metadata": {
        "id": "BtmAkWJlmoGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ListDictDataset(Dataset):\n",
        "    def __init__(self, list_of_dicts):\n",
        "        self.list_of_dicts = list_of_dicts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_of_dicts)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.list_of_dicts[index]\n",
        "\n",
        "dataset = train\n",
        "#dataset = ListDictDataset(train)\n",
        "type(dataset)"
      ],
      "metadata": {
        "id": "NJ9yqCLUJoJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfcbfdfa-798f-49fe-cf6a-dd5476e5d5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creem un dataloader per processar bé totes les traduccions, on només afegirem els index de les paraules al diccionari corresponent segons l idioma, que és el que ens servirà per fer l embedding de les frases"
      ],
      "metadata": {
        "id": "xKdeJ49t2H72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_collate_fn(pad_index):\n",
        "    def collate_fn(batch):\n",
        "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
        "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
        "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)  #Fem servir padding com relleno\n",
        "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
        "        batch = {\n",
        "            \"en_ids\": batch_en_ids,\n",
        "            \"de_ids\": batch_de_ids,\n",
        "        }\n",
        "        return batch\n",
        "\n",
        "    return collate_fn"
      ],
      "metadata": {
        "id": "OAU-5maIOy_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
        "    collate_fn = get_collate_fn(pad_index)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=shuffle,\n",
        "    )\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "-nXDbcmAO00R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_data_loader = get_data_loader(dataset, batch_size, pad_index, shuffle=True)"
      ],
      "metadata": {
        "id": "IX8p51uiO2vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_loader"
      ],
      "metadata": {
        "id": "6r-SqdWWPI7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82d1dcc7-d02f-4aee-9b5c-75a50ea357df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7de4274eb0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cla"
      ],
      "metadata": {
        "id": "zpUhnCxzpNSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional=True)\n",
        "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
        "        self.dropout = nn.Dropout(dropout)  # recordem: dropout desactiva un % de neurones i així evita l'overfitting\n",
        "\n",
        "    def forward(self, src):\n",
        "        # src = [src length, batch size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # embedded = [src length, batch size, embedding dim]\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        # outputs = [src length, batch size, hidden dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
        "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        # outputs are always from the last layer\n",
        "        # hidden [-2, :, : ] is the last of the forwards RNN\n",
        "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        # initial decoder hidden is final hidden state of the forwards and backwards\n",
        "        # encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(\n",
        "            self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "        )\n",
        "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
        "        # hidden = [batch size, decoder hidden dim]\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "Z47jVMWCPLLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn_fc = nn.Linear(\n",
        "            (encoder_hidden_dim * 2) + decoder_hidden_dim, decoder_hidden_dim\n",
        "        )\n",
        "        self.v_fc = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden = [batch size, decoder hidden dim]\n",
        "        # encoder_outputs = [src length, batch size, encoder hidden dim * 2]\n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_length = encoder_outputs.shape[0]\n",
        "        # repeat decoder hidden state src_length times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_length, 1)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # hidden = [batch size, src length, decoder hidden dim]\n",
        "        # encoder_outputs = [batch size, src length, encoder hidden dim * 2]\n",
        "        energy = torch.tanh(self.attn_fc(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        # energy = [batch size, src length, decoder hidden dim]\n",
        "        attention = self.v_fc(energy).squeeze(2)\n",
        "        # attention = [batch size, src length]\n",
        "        return torch.softmax(attention, dim=1)"
      ],
      "metadata": {
        "id": "CnTBYOVqqJ2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        output_dim,\n",
        "        embedding_dim,\n",
        "        encoder_hidden_dim,\n",
        "        decoder_hidden_dim,\n",
        "        dropout,\n",
        "        attention,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
        "        self.rnn = nn.GRU((encoder_hidden_dim * 2) + embedding_dim, decoder_hidden_dim)\n",
        "        self.fc_out = nn.Linear(\n",
        "            (encoder_hidden_dim * 2) + decoder_hidden_dim + embedding_dim, output_dim\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        # input = [batch size]\n",
        "        # hidden = [batch size, decoder hidden dim]\n",
        "        # encoder_outputs = [src length, batch size, encoder hidden dim * 2]\n",
        "        input = input.unsqueeze(0)\n",
        "        # input = [1, batch size]\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # embedded = [1, batch size, embedding dim]\n",
        "        a = self.attention(hidden, encoder_outputs)\n",
        "        # a = [batch size, src length]\n",
        "        a = a.unsqueeze(1)\n",
        "        # a = [batch size, 1, src length]\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        # encoder_outputs = [batch size, src length, encoder hidden dim * 2]\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        # weighted = [batch size, 1, encoder hidden dim * 2]\n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        # weighted = [1, batch size, encoder hidden dim * 2]\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        # rnn_input = [1, batch size, (encoder hidden dim * 2) + embedding dim]\n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        # output = [seq length, batch size, decoder hid dim * n directions]\n",
        "        # hidden = [n layers * n directions, batch size, decoder hid dim]\n",
        "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        # output = [1, batch size, decoder hidden dim]\n",
        "        # hidden = [1, batch size, decoder hidden dim]\n",
        "        # this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
        "        # prediction = [batch size, output dim]\n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "metadata": {
        "id": "IyMddtl9qR8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio):\n",
        "        # src = [src length, batch size]\n",
        "        # trg = [trg length, batch size]\n",
        "        # teacher_forcing_ratio is probability to use teacher forcing\n",
        "        # e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "        batch_size = src.shape[1]\n",
        "        trg_length = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
        "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
        "        # hidden = [batch size, decoder hidden dim]\n",
        "        # first input to the decoder is the <sos> tokens\n",
        "        input = trg[0, :]\n",
        "        for t in range(1, trg_length):\n",
        "            # insert input token embedding, previous hidden state and all encoder hidden states\n",
        "            # receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
        "            # output = [batch size, output dim]\n",
        "            # hidden = [n layers, batch size, decoder hidden dim]\n",
        "            # place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            # decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            # get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1)\n",
        "            # if teacher forcing, use actual next token as next input\n",
        "            # if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "            # input = [batch size]\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "3M0T27TdqUus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valors amb el que anirem probant per millorar l'eficiència del model"
      ],
      "metadata": {
        "id": "pHqw9aKbrY3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = len(de_vocab)\n",
        "output_dim = len(en_vocab)\n",
        "encoder_embedding_dim = 256\n",
        "decoder_embedding_dim = 256\n",
        "encoder_hidden_dim = 512\n",
        "decoder_hidden_dim = 512\n",
        "encoder_dropout = 0.5\n",
        "decoder_dropout = 0.5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "attention = Attention(encoder_hidden_dim, decoder_hidden_dim)\n",
        "\n",
        "encoder = Encoder(\n",
        "    input_dim,\n",
        "    encoder_embedding_dim,\n",
        "    encoder_hidden_dim,\n",
        "    decoder_hidden_dim,\n",
        "    encoder_dropout,\n",
        ")\n",
        "\n",
        "decoder = Decoder(\n",
        "    output_dim,\n",
        "    decoder_embedding_dim,\n",
        "    encoder_hidden_dim,\n",
        "    decoder_hidden_dim,\n",
        "    decoder_dropout,\n",
        "    attention,\n",
        ")\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)"
      ],
      "metadata": {
        "id": "dXeBljfeqVQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada paràmetre representa el weight o bias d'una capa (ih=input, hh=hidden) en el recorregut d'anada per calcular el loss o el de tornada que actualitza el gradient (reverse)"
      ],
      "metadata": {
        "id": "EJWFQIcuzAQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for p in model.named_parameters(): print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfyhJ1E-x--R",
        "outputId": "d1ff0af0-0f90-44e7-b2d9-127d45d6c7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('encoder.embedding.weight', Parameter containing:\n",
            "tensor([[ 2.1168e-03, -8.8684e-03, -3.3382e-04,  ..., -1.6067e-02,\n",
            "          2.2180e-02, -1.2415e-02],\n",
            "        [-1.0009e-02,  9.2787e-03, -2.7888e-03,  ...,  1.3415e-03,\n",
            "          1.1938e-02,  2.9915e-03],\n",
            "        [-2.5358e-03, -7.9588e-04, -1.7207e-02,  ..., -6.2139e-03,\n",
            "          1.7234e-02,  1.9419e-02],\n",
            "        ...,\n",
            "        [-2.1381e-03, -3.7756e-03, -6.6067e-03,  ...,  9.5179e-04,\n",
            "          1.5396e-02,  8.8129e-03],\n",
            "        [-3.1412e-05,  4.6364e-03, -9.6797e-03,  ...,  1.3090e-02,\n",
            "          1.5145e-02,  5.9216e-04],\n",
            "        [ 2.5885e-03, -2.4042e-03,  4.5074e-03,  ...,  7.3129e-03,\n",
            "         -1.5921e-02, -8.8536e-03]], requires_grad=True))\n",
            "('encoder.rnn.weight_ih_l0', Parameter containing:\n",
            "tensor([[ 1.2817e-02, -1.0834e-02,  1.7849e-03,  ..., -1.0800e-02,\n",
            "          8.9175e-05, -6.6825e-04],\n",
            "        [ 1.1681e-02,  1.5100e-02, -2.4064e-03,  ...,  1.4649e-02,\n",
            "          3.9045e-03, -2.0727e-03],\n",
            "        [ 1.2053e-02, -5.7004e-03, -1.3056e-02,  ..., -1.3039e-02,\n",
            "          4.1758e-03, -1.1200e-02],\n",
            "        ...,\n",
            "        [ 3.5099e-03,  2.3817e-02, -5.3698e-03,  ..., -1.0861e-02,\n",
            "         -2.0197e-02, -9.6524e-03],\n",
            "        [-4.4412e-03, -1.1423e-02, -9.1099e-03,  ..., -5.3443e-03,\n",
            "          7.8767e-03,  1.0600e-03],\n",
            "        [ 1.5169e-02,  1.1141e-03,  3.9853e-03,  ..., -2.4154e-02,\n",
            "         -3.8380e-03, -1.4994e-02]], requires_grad=True))\n",
            "('encoder.rnn.weight_hh_l0', Parameter containing:\n",
            "tensor([[-0.0203,  0.0039,  0.0026,  ..., -0.0071,  0.0101, -0.0006],\n",
            "        [-0.0070,  0.0002, -0.0045,  ...,  0.0188, -0.0094, -0.0232],\n",
            "        [ 0.0098, -0.0028,  0.0083,  ...,  0.0061,  0.0006, -0.0042],\n",
            "        ...,\n",
            "        [-0.0027, -0.0099,  0.0037,  ...,  0.0026,  0.0036, -0.0124],\n",
            "        [-0.0012,  0.0050,  0.0010,  ..., -0.0202, -0.0082,  0.0054],\n",
            "        [-0.0118, -0.0067,  0.0078,  ...,  0.0145,  0.0004, -0.0158]],\n",
            "       requires_grad=True))\n",
            "('encoder.rnn.bias_ih_l0', Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))\n",
            "('encoder.rnn.bias_hh_l0', Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))\n",
            "('encoder.rnn.weight_ih_l0_reverse', Parameter containing:\n",
            "tensor([[ 0.0023, -0.0038, -0.0036,  ..., -0.0065,  0.0017,  0.0121],\n",
            "        [ 0.0066, -0.0064,  0.0128,  ..., -0.0057,  0.0150, -0.0126],\n",
            "        [-0.0072, -0.0016, -0.0063,  ...,  0.0051,  0.0072, -0.0004],\n",
            "        ...,\n",
            "        [-0.0012,  0.0133, -0.0026,  ..., -0.0157, -0.0086,  0.0093],\n",
            "        [ 0.0098, -0.0114, -0.0086,  ...,  0.0040, -0.0003,  0.0009],\n",
            "        [-0.0106, -0.0024, -0.0030,  ..., -0.0151,  0.0053, -0.0119]],\n",
            "       requires_grad=True))\n",
            "('encoder.rnn.weight_hh_l0_reverse', Parameter containing:\n",
            "tensor([[ 1.1594e-03,  1.5885e-02, -9.4259e-03,  ..., -4.2685e-03,\n",
            "         -7.1008e-03, -1.5274e-02],\n",
            "        [-8.0404e-03, -8.8622e-03,  8.8075e-03,  ..., -1.5858e-02,\n",
            "         -6.0860e-03,  7.0704e-03],\n",
            "        [ 1.4396e-02,  3.1529e-03, -1.2928e-02,  ...,  1.5263e-03,\n",
            "         -6.6089e-03,  1.8704e-02],\n",
            "        ...,\n",
            "        [-5.3268e-03, -2.7779e-04, -1.4955e-05,  ..., -4.5841e-03,\n",
            "         -8.5040e-03, -1.6557e-02],\n",
            "        [ 1.8201e-04, -7.7016e-03,  1.3839e-02,  ...,  2.5891e-02,\n",
            "         -1.5208e-03, -2.3200e-02],\n",
            "        [-2.0369e-02, -2.8608e-03,  6.0565e-03,  ...,  2.5219e-04,\n",
            "         -4.5362e-03, -5.0883e-03]], requires_grad=True))\n",
            "('encoder.rnn.bias_ih_l0_reverse', Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))\n",
            "('encoder.rnn.bias_hh_l0_reverse', Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))\n",
            "('encoder.fc.weight', Parameter containing:\n",
            "tensor([[ 4.1160e-04,  2.2446e-03,  2.7817e-03,  ...,  5.3442e-04,\n",
            "         -9.9637e-03,  1.4422e-03],\n",
            "        [-1.5694e-02, -1.8576e-02,  9.6450e-03,  ..., -1.7694e-02,\n",
            "         -7.6833e-03, -1.0366e-02],\n",
            "        [ 7.5675e-03, -1.8107e-02, -8.5142e-03,  ..., -3.6103e-03,\n",
            "          4.0155e-03, -1.7420e-02],\n",
            "        ...,\n",
            "        [-6.0947e-03, -5.7548e-05, -1.2439e-02,  ...,  9.2860e-04,\n",
            "          4.3208e-03,  1.8650e-02],\n",
            "        [-7.4816e-03, -4.1911e-04,  6.8079e-03,  ...,  5.2533e-03,\n",
            "          7.4926e-03,  3.4326e-03],\n",
            "        [-5.5027e-03, -4.4079e-03,  4.7153e-03,  ..., -1.5627e-03,\n",
            "          1.6441e-02, -7.7422e-04]], requires_grad=True))\n",
            "('encoder.fc.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))\n",
            "('decoder.attention.attn_fc.weight', Parameter containing:\n",
            "tensor([[-1.5527e-03, -1.5401e-02, -5.2378e-03,  ..., -1.9095e-03,\n",
            "          9.3149e-03,  1.1461e-03],\n",
            "        [ 1.2965e-02, -1.4130e-02,  2.7052e-03,  ...,  2.6527e-03,\n",
            "          1.3906e-02,  1.2558e-03],\n",
            "        [ 8.5479e-03,  2.4489e-02,  4.0461e-03,  ...,  2.9557e-02,\n",
            "         -9.6064e-04,  2.8510e-05],\n",
            "        ...,\n",
            "        [-8.6251e-03, -3.2471e-03,  6.5112e-03,  ...,  4.9144e-03,\n",
            "         -2.3696e-03,  1.3709e-03],\n",
            "        [ 1.2744e-02, -1.8332e-02,  1.1512e-02,  ...,  1.7136e-03,\n",
            "         -1.0642e-02, -2.7882e-03],\n",
            "        [ 4.8122e-03, -9.0493e-03,  3.1879e-03,  ...,  6.9276e-03,\n",
            "         -2.7499e-03, -4.0151e-04]], requires_grad=True))\n",
            "('decoder.attention.attn_fc.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))\n",
            "('decoder.attention.v_fc.weight', Parameter containing:\n",
            "tensor([[-8.3236e-03, -1.1955e-02,  1.4442e-02,  1.1372e-02,  1.2524e-02,\n",
            "          2.7135e-02, -5.8307e-03, -2.7280e-02, -3.8960e-03,  5.6812e-03,\n",
            "          3.5566e-03, -5.2252e-03,  2.1272e-02,  1.0991e-02, -6.6376e-03,\n",
            "          1.2249e-02,  4.7922e-03, -3.6138e-03, -8.1356e-03, -2.8089e-03,\n",
            "          3.3300e-03,  1.6684e-02, -1.7436e-02, -1.1467e-03, -2.4578e-03,\n",
            "          1.2230e-02,  8.5948e-03, -7.2046e-04, -3.4538e-03, -1.9244e-02,\n",
            "         -1.6485e-03,  2.1976e-02,  1.5503e-02, -3.1797e-04,  1.0180e-02,\n",
            "          8.5303e-03, -1.6103e-02,  1.4868e-03, -6.0701e-03, -1.0849e-02,\n",
            "          1.7397e-02,  1.5055e-02, -1.6369e-02,  1.1040e-03, -1.0753e-02,\n",
            "         -4.1771e-03, -6.2505e-03, -2.0385e-03,  2.9294e-03,  1.5790e-03,\n",
            "          8.3643e-03, -6.7133e-03, -4.8510e-03,  6.9113e-03,  9.8084e-03,\n",
            "         -5.5331e-04, -1.1356e-02, -2.0093e-03, -1.5406e-04, -9.5540e-04,\n",
            "          2.6270e-02, -8.4972e-03, -6.2284e-04, -1.0569e-02,  1.5992e-03,\n",
            "         -2.3569e-02,  1.5935e-02,  5.6672e-03,  1.2177e-02, -2.1149e-02,\n",
            "         -2.7388e-02, -1.4374e-02, -6.2587e-03, -5.9894e-03, -1.1412e-02,\n",
            "          1.8742e-02,  4.9487e-03, -5.6326e-03, -1.0632e-03,  1.2264e-02,\n",
            "          8.5276e-03, -3.9805e-03,  2.0568e-02, -8.3128e-03,  6.4579e-03,\n",
            "          1.2927e-02, -1.4407e-02,  8.3794e-03, -5.4061e-04,  1.2553e-02,\n",
            "         -7.5150e-03, -5.2015e-03,  9.9664e-03,  6.3275e-03,  8.4744e-03,\n",
            "         -1.1691e-03, -6.9508e-03, -9.6332e-04, -1.5492e-02, -2.2189e-03,\n",
            "          3.3787e-03,  5.0280e-03,  2.9549e-03,  9.2828e-04,  4.7765e-03,\n",
            "          3.1555e-03, -1.7529e-02, -2.0639e-03,  1.6268e-02, -7.9912e-03,\n",
            "          1.8433e-03,  8.7596e-03,  4.9321e-03,  1.1082e-02,  1.0555e-02,\n",
            "         -1.6911e-03, -6.2136e-03,  8.5398e-03,  5.8390e-03,  1.3652e-03,\n",
            "         -7.5538e-03, -2.2435e-04, -6.8261e-03,  4.9427e-03,  7.9673e-03,\n",
            "          8.1442e-03,  5.5850e-03,  2.9629e-03,  1.1488e-03, -1.1227e-02,\n",
            "         -6.7360e-03, -1.4035e-02,  1.5651e-02, -1.2099e-02, -8.9880e-03,\n",
            "         -1.0055e-03, -1.0659e-03,  8.0971e-03, -5.9774e-03,  8.5595e-03,\n",
            "          2.0393e-02,  1.1718e-02, -1.3158e-04,  1.2494e-02,  7.5866e-03,\n",
            "          1.6439e-02,  1.1770e-02,  5.5186e-03,  1.8072e-02, -8.4626e-03,\n",
            "          1.4859e-02, -4.4461e-03, -6.5696e-03,  1.1811e-02,  7.8499e-03,\n",
            "         -3.1592e-03,  9.2723e-04, -8.6124e-03, -1.6692e-03,  1.1556e-02,\n",
            "          3.7134e-03, -1.3226e-02,  5.8611e-03,  3.7184e-03,  3.2461e-03,\n",
            "         -4.0610e-03, -1.5660e-03, -1.7049e-02, -3.6880e-04, -9.4976e-03,\n",
            "         -9.1202e-03, -4.5646e-03,  2.2151e-02,  6.6617e-03, -1.9954e-02,\n",
            "         -6.9823e-03,  6.1467e-03, -4.6841e-03, -1.0828e-03, -7.9896e-03,\n",
            "         -1.5773e-02, -5.3471e-03,  2.5880e-03,  8.7137e-03,  1.5287e-02,\n",
            "          1.6497e-03,  1.6417e-02,  8.2209e-03, -4.1186e-03,  1.4376e-03,\n",
            "          1.2355e-04,  1.9046e-03,  4.2713e-03,  1.3282e-02,  9.0116e-03,\n",
            "         -1.7868e-02, -4.0997e-04, -8.0441e-03, -2.1865e-02, -3.1874e-03,\n",
            "          1.7793e-02, -8.9083e-04,  3.0451e-04, -8.5681e-03, -5.9518e-03,\n",
            "          8.1174e-03,  1.5051e-02, -6.1810e-03, -8.4053e-03,  1.3830e-02,\n",
            "          1.3400e-02,  1.6472e-02, -6.6404e-03, -1.3628e-02,  1.2781e-02,\n",
            "          2.1924e-03,  1.4915e-02,  2.1685e-03, -8.6995e-03, -5.5474e-03,\n",
            "         -8.7751e-04,  5.1512e-04,  1.7785e-02,  4.5064e-03,  7.2932e-03,\n",
            "         -1.1730e-02,  1.1103e-02, -1.2803e-02, -1.8407e-04,  2.3944e-03,\n",
            "          8.6650e-03,  9.5408e-04,  5.0930e-03,  9.3256e-03, -2.2247e-03,\n",
            "          1.0277e-02, -2.5310e-03, -4.5905e-04,  2.9667e-03,  4.6787e-04,\n",
            "          1.4040e-02, -2.3045e-02,  3.1183e-06,  6.7639e-03,  5.9581e-03,\n",
            "          8.3186e-03,  1.8308e-02, -2.3276e-03,  3.2781e-04, -5.7344e-03,\n",
            "         -1.0030e-02, -8.8161e-03, -9.3416e-03,  6.7653e-03, -4.2932e-03,\n",
            "         -1.0305e-02, -3.7368e-03,  3.5578e-03,  9.6689e-03, -4.0391e-04,\n",
            "         -2.7644e-03, -8.2120e-03,  6.6907e-03,  1.0952e-02, -7.8506e-03,\n",
            "          5.3262e-03,  8.8041e-04,  1.5489e-02, -1.5750e-02,  1.0256e-02,\n",
            "         -3.6477e-03,  3.7881e-03,  1.0808e-02,  1.9235e-02, -7.1602e-03,\n",
            "         -6.5018e-03,  9.0487e-04,  7.6971e-03, -1.8777e-03, -3.7342e-03,\n",
            "         -1.4923e-02, -2.0232e-03, -9.5600e-03,  4.1606e-03, -9.8743e-03,\n",
            "          1.2977e-02,  1.7852e-02,  1.8242e-02, -6.9371e-03,  2.4211e-02,\n",
            "          2.1169e-02,  2.3626e-03,  1.1132e-03,  1.3439e-03,  4.1918e-04,\n",
            "          1.5127e-03,  8.3445e-03,  1.0518e-03, -2.3936e-03, -7.4527e-03,\n",
            "          1.0504e-02, -2.1389e-02, -7.8274e-03, -3.2823e-03, -4.0578e-03,\n",
            "         -5.2134e-03, -5.1620e-03, -1.1042e-02,  2.3842e-02, -2.8036e-03,\n",
            "         -1.9752e-02, -1.0621e-02,  1.5729e-02, -4.7306e-03, -1.1472e-02,\n",
            "         -4.5405e-03, -1.8511e-04, -1.5929e-03, -1.3044e-02,  2.8489e-03,\n",
            "         -6.0452e-03, -2.3317e-03,  1.0988e-02, -3.6564e-04,  5.3358e-03,\n",
            "         -2.1143e-03,  6.1095e-03,  1.0488e-03, -6.1048e-04, -1.8802e-03,\n",
            "          1.1768e-02,  2.1721e-04,  3.5147e-03,  6.7570e-03,  6.2087e-03,\n",
            "          6.0041e-03,  4.6254e-03, -1.0406e-02, -8.2701e-03, -1.8380e-03,\n",
            "          1.6511e-03,  1.6801e-02,  1.5306e-03,  7.2609e-03, -6.4243e-03,\n",
            "          5.6018e-03, -1.1607e-02, -6.8090e-03,  3.5485e-03,  2.9986e-03,\n",
            "         -2.7754e-03,  2.0668e-02, -5.9631e-03,  7.9390e-04,  1.4452e-03,\n",
            "         -4.7812e-03,  5.2699e-03,  8.2727e-03,  1.0473e-02,  2.0009e-03,\n",
            "         -8.7513e-03, -4.4630e-03, -1.3077e-02, -2.6504e-03, -8.3966e-04,\n",
            "          1.5518e-03, -1.8939e-02, -1.8627e-02, -4.3821e-05, -2.1747e-03,\n",
            "          1.4096e-02,  4.9861e-03, -1.0062e-02, -2.6721e-03,  1.0334e-02,\n",
            "         -2.3908e-03, -2.0853e-03,  1.2335e-03,  3.6953e-08, -4.0035e-04,\n",
            "          2.2538e-02,  3.8887e-03,  1.3148e-02, -3.3673e-03, -5.2919e-03,\n",
            "         -6.7603e-03, -9.0466e-03,  6.8763e-03, -2.7153e-04, -1.3809e-02,\n",
            "          4.7060e-03,  3.9600e-03, -1.1301e-03, -2.9161e-03,  3.8353e-03,\n",
            "          1.5836e-02, -2.8845e-03, -4.3257e-03, -9.5109e-03, -1.1623e-03,\n",
            "          3.9024e-03, -1.2383e-04,  8.6588e-03, -6.6189e-03, -3.4719e-03,\n",
            "          4.2813e-03,  3.8377e-04, -1.0937e-02,  1.2215e-02,  1.4025e-02,\n",
            "         -1.1307e-03,  2.1932e-03, -1.1713e-03,  4.0234e-03,  1.5213e-02,\n",
            "         -8.2827e-03,  6.3621e-03,  1.3711e-02, -3.6113e-03,  1.0772e-02,\n",
            "         -1.0618e-02,  1.2495e-03, -1.3037e-02, -1.0050e-02,  6.0683e-03,\n",
            "         -2.6591e-03,  1.5093e-03, -5.3270e-03, -3.9659e-03,  3.2289e-03,\n",
            "          8.5864e-03,  2.5174e-03,  6.0115e-03,  1.1905e-02,  1.0749e-02,\n",
            "         -6.0847e-03,  7.0071e-03,  1.8376e-03, -8.1354e-03, -2.4499e-02,\n",
            "         -5.6661e-03,  2.5762e-02, -9.0869e-03, -1.5484e-03, -1.4350e-03,\n",
            "         -1.5257e-03,  1.8635e-02, -1.4792e-03,  1.6812e-03, -1.2040e-02,\n",
            "          4.5657e-03, -2.1824e-02, -5.9396e-03,  5.4775e-03, -1.3705e-03,\n",
            "          9.1864e-03,  5.4582e-03,  1.1486e-02, -9.6711e-03,  1.7811e-03,\n",
            "         -2.1679e-03, -5.6952e-03,  2.4220e-03,  6.4811e-03, -4.5955e-04,\n",
            "         -1.4729e-02, -3.3512e-03,  7.2137e-03, -4.1840e-03, -3.9352e-03,\n",
            "          1.8836e-02, -5.0016e-03,  1.0803e-02, -7.1893e-03, -4.9978e-03,\n",
            "          9.9435e-03, -9.2497e-03, -1.7412e-02, -8.3613e-03, -1.6402e-02,\n",
            "         -1.0753e-02,  4.1495e-04,  2.9831e-02, -6.7648e-03, -2.3756e-02,\n",
            "         -1.1404e-03,  2.3296e-03,  1.5690e-03,  9.3441e-03, -4.4036e-03,\n",
            "         -1.4055e-02, -1.2296e-02,  5.9235e-03, -9.4258e-03, -6.0423e-03,\n",
            "         -1.6252e-02,  2.0186e-02, -2.0223e-04,  3.7986e-03,  2.6177e-04,\n",
            "          5.2196e-03, -3.9315e-03,  1.6960e-02,  1.2301e-02, -2.0914e-02,\n",
            "         -4.7771e-03, -8.5589e-03,  2.4387e-02,  1.1563e-02, -1.2528e-02,\n",
            "         -2.0921e-02, -1.6102e-02]], requires_grad=True))\n",
            "('decoder.embedding.weight', Parameter containing:\n",
            "tensor([[ 0.0261,  0.0182, -0.0021,  ..., -0.0040, -0.0045, -0.0233],\n",
            "        [ 0.0035, -0.0050, -0.0111,  ...,  0.0215, -0.0143,  0.0021],\n",
            "        [-0.0079, -0.0149,  0.0090,  ..., -0.0240,  0.0025, -0.0151],\n",
            "        ...,\n",
            "        [ 0.0044,  0.0176,  0.0063,  ..., -0.0021, -0.0076,  0.0037],\n",
            "        [ 0.0169,  0.0050,  0.0062,  ...,  0.0058,  0.0116, -0.0015],\n",
            "        [-0.0049, -0.0130, -0.0005,  ..., -0.0035, -0.0065, -0.0094]],\n",
            "       requires_grad=True))\n",
            "('decoder.rnn.weight_ih_l0', Parameter containing:\n",
            "tensor([[-1.3346e-02,  4.9142e-03,  2.4095e-03,  ...,  1.2706e-02,\n",
            "          5.9349e-03,  8.2871e-03],\n",
            "        [-1.1347e-02,  3.5384e-03,  8.5065e-03,  ...,  1.1713e-02,\n",
            "          1.5137e-03,  1.5244e-02],\n",
            "        [ 1.0767e-03, -4.0444e-03, -1.8080e-03,  ..., -1.1232e-02,\n",
            "         -1.9007e-02, -7.0704e-03],\n",
            "        ...,\n",
            "        [-3.6899e-03,  2.1554e-03, -6.1473e-03,  ..., -1.9017e-02,\n",
            "         -3.5464e-03, -9.3668e-03],\n",
            "        [-2.8604e-03,  6.2260e-04,  6.6550e-03,  ...,  9.1159e-03,\n",
            "          6.5451e-03,  4.3001e-06],\n",
            "        [-1.9700e-05,  3.6454e-03, -1.4572e-02,  ..., -2.7933e-03,\n",
            "         -5.5957e-03,  7.7887e-03]], requires_grad=True))\n",
            "('decoder.rnn.weight_hh_l0', Parameter containing:\n",
            "tensor([[-0.0040,  0.0094, -0.0005,  ...,  0.0002,  0.0092, -0.0021],\n",
            "        [ 0.0044,  0.0011,  0.0074,  ..., -0.0008, -0.0139,  0.0010],\n",
            "        [-0.0018,  0.0249, -0.0134,  ..., -0.0046, -0.0044,  0.0152],\n",
            "        ...,\n",
            "        [ 0.0155,  0.0007,  0.0006,  ...,  0.0099,  0.0115,  0.0016],\n",
            "        [ 0.0012,  0.0064,  0.0151,  ..., -0.0061,  0.0057,  0.0079],\n",
            "        [-0.0101, -0.0060, -0.0121,  ...,  0.0006, -0.0049,  0.0019]],\n",
            "       requires_grad=True))\n",
            "('decoder.rnn.bias_ih_l0', Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))\n",
            "('decoder.rnn.bias_hh_l0', Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))\n",
            "('decoder.fc_out.weight', Parameter containing:\n",
            "tensor([[-0.0070,  0.0119,  0.0124,  ..., -0.0077, -0.0014,  0.0215],\n",
            "        [-0.0144, -0.0022,  0.0059,  ..., -0.0221,  0.0003, -0.0100],\n",
            "        [ 0.0126,  0.0094, -0.0193,  ..., -0.0031,  0.0006,  0.0002],\n",
            "        ...,\n",
            "        [-0.0137,  0.0005, -0.0100,  ...,  0.0001,  0.0087, -0.0015],\n",
            "        [-0.0006,  0.0119,  0.0092,  ...,  0.0132,  0.0003,  0.0074],\n",
            "        [ 0.0068, -0.0085, -0.0112,  ...,  0.0055,  0.0115,  0.0050]],\n",
            "       requires_grad=True))\n",
            "('decoder.fc_out.bias', Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if \"weight\" in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)  # pesos molt propers a 0, desviació del 1%, perill de vanishing\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYb4UwJlufAd",
        "outputId": "8bc6753a-189b-45fe-8bd5-8a539ca4afbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(297, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(262, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=262, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad),model.parameters()\n",
        "\n",
        "a,b = count_parameters(model)\n",
        "suma=0\n",
        "for x in b:\n",
        "  print(x)\n",
        "\n",
        "print(f\"The model has {a:,} trainable parameters\",suma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMWLPvUpvdBH",
        "outputId": "a1eac95e-87ff-4eaa-86f4-8a62a1d1722e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 2.1168e-03, -8.8684e-03, -3.3382e-04,  ..., -1.6067e-02,\n",
            "          2.2180e-02, -1.2415e-02],\n",
            "        [-1.0009e-02,  9.2787e-03, -2.7888e-03,  ...,  1.3415e-03,\n",
            "          1.1938e-02,  2.9915e-03],\n",
            "        [-2.5358e-03, -7.9588e-04, -1.7207e-02,  ..., -6.2139e-03,\n",
            "          1.7234e-02,  1.9419e-02],\n",
            "        ...,\n",
            "        [-2.1381e-03, -3.7756e-03, -6.6067e-03,  ...,  9.5179e-04,\n",
            "          1.5396e-02,  8.8129e-03],\n",
            "        [-3.1412e-05,  4.6364e-03, -9.6797e-03,  ...,  1.3090e-02,\n",
            "          1.5145e-02,  5.9216e-04],\n",
            "        [ 2.5885e-03, -2.4042e-03,  4.5074e-03,  ...,  7.3129e-03,\n",
            "         -1.5921e-02, -8.8536e-03]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 1.2817e-02, -1.0834e-02,  1.7849e-03,  ..., -1.0800e-02,\n",
            "          8.9175e-05, -6.6825e-04],\n",
            "        [ 1.1681e-02,  1.5100e-02, -2.4064e-03,  ...,  1.4649e-02,\n",
            "          3.9045e-03, -2.0727e-03],\n",
            "        [ 1.2053e-02, -5.7004e-03, -1.3056e-02,  ..., -1.3039e-02,\n",
            "          4.1758e-03, -1.1200e-02],\n",
            "        ...,\n",
            "        [ 3.5099e-03,  2.3817e-02, -5.3698e-03,  ..., -1.0861e-02,\n",
            "         -2.0197e-02, -9.6524e-03],\n",
            "        [-4.4412e-03, -1.1423e-02, -9.1099e-03,  ..., -5.3443e-03,\n",
            "          7.8767e-03,  1.0600e-03],\n",
            "        [ 1.5169e-02,  1.1141e-03,  3.9853e-03,  ..., -2.4154e-02,\n",
            "         -3.8380e-03, -1.4994e-02]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0203,  0.0039,  0.0026,  ..., -0.0071,  0.0101, -0.0006],\n",
            "        [-0.0070,  0.0002, -0.0045,  ...,  0.0188, -0.0094, -0.0232],\n",
            "        [ 0.0098, -0.0028,  0.0083,  ...,  0.0061,  0.0006, -0.0042],\n",
            "        ...,\n",
            "        [-0.0027, -0.0099,  0.0037,  ...,  0.0026,  0.0036, -0.0124],\n",
            "        [-0.0012,  0.0050,  0.0010,  ..., -0.0202, -0.0082,  0.0054],\n",
            "        [-0.0118, -0.0067,  0.0078,  ...,  0.0145,  0.0004, -0.0158]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0023, -0.0038, -0.0036,  ..., -0.0065,  0.0017,  0.0121],\n",
            "        [ 0.0066, -0.0064,  0.0128,  ..., -0.0057,  0.0150, -0.0126],\n",
            "        [-0.0072, -0.0016, -0.0063,  ...,  0.0051,  0.0072, -0.0004],\n",
            "        ...,\n",
            "        [-0.0012,  0.0133, -0.0026,  ..., -0.0157, -0.0086,  0.0093],\n",
            "        [ 0.0098, -0.0114, -0.0086,  ...,  0.0040, -0.0003,  0.0009],\n",
            "        [-0.0106, -0.0024, -0.0030,  ..., -0.0151,  0.0053, -0.0119]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 1.1594e-03,  1.5885e-02, -9.4259e-03,  ..., -4.2685e-03,\n",
            "         -7.1008e-03, -1.5274e-02],\n",
            "        [-8.0404e-03, -8.8622e-03,  8.8075e-03,  ..., -1.5858e-02,\n",
            "         -6.0860e-03,  7.0704e-03],\n",
            "        [ 1.4396e-02,  3.1529e-03, -1.2928e-02,  ...,  1.5263e-03,\n",
            "         -6.6089e-03,  1.8704e-02],\n",
            "        ...,\n",
            "        [-5.3268e-03, -2.7779e-04, -1.4955e-05,  ..., -4.5841e-03,\n",
            "         -8.5040e-03, -1.6557e-02],\n",
            "        [ 1.8201e-04, -7.7016e-03,  1.3839e-02,  ...,  2.5891e-02,\n",
            "         -1.5208e-03, -2.3200e-02],\n",
            "        [-2.0369e-02, -2.8608e-03,  6.0565e-03,  ...,  2.5219e-04,\n",
            "         -4.5362e-03, -5.0883e-03]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 4.1160e-04,  2.2446e-03,  2.7817e-03,  ...,  5.3442e-04,\n",
            "         -9.9637e-03,  1.4422e-03],\n",
            "        [-1.5694e-02, -1.8576e-02,  9.6450e-03,  ..., -1.7694e-02,\n",
            "         -7.6833e-03, -1.0366e-02],\n",
            "        [ 7.5675e-03, -1.8107e-02, -8.5142e-03,  ..., -3.6103e-03,\n",
            "          4.0155e-03, -1.7420e-02],\n",
            "        ...,\n",
            "        [-6.0947e-03, -5.7548e-05, -1.2439e-02,  ...,  9.2860e-04,\n",
            "          4.3208e-03,  1.8650e-02],\n",
            "        [-7.4816e-03, -4.1911e-04,  6.8079e-03,  ...,  5.2533e-03,\n",
            "          7.4926e-03,  3.4326e-03],\n",
            "        [-5.5027e-03, -4.4079e-03,  4.7153e-03,  ..., -1.5627e-03,\n",
            "          1.6441e-02, -7.7422e-04]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-1.5527e-03, -1.5401e-02, -5.2378e-03,  ..., -1.9095e-03,\n",
            "          9.3149e-03,  1.1461e-03],\n",
            "        [ 1.2965e-02, -1.4130e-02,  2.7052e-03,  ...,  2.6527e-03,\n",
            "          1.3906e-02,  1.2558e-03],\n",
            "        [ 8.5479e-03,  2.4489e-02,  4.0461e-03,  ...,  2.9557e-02,\n",
            "         -9.6064e-04,  2.8510e-05],\n",
            "        ...,\n",
            "        [-8.6251e-03, -3.2471e-03,  6.5112e-03,  ...,  4.9144e-03,\n",
            "         -2.3696e-03,  1.3709e-03],\n",
            "        [ 1.2744e-02, -1.8332e-02,  1.1512e-02,  ...,  1.7136e-03,\n",
            "         -1.0642e-02, -2.7882e-03],\n",
            "        [ 4.8122e-03, -9.0493e-03,  3.1879e-03,  ...,  6.9276e-03,\n",
            "         -2.7499e-03, -4.0151e-04]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-8.3236e-03, -1.1955e-02,  1.4442e-02,  1.1372e-02,  1.2524e-02,\n",
            "          2.7135e-02, -5.8307e-03, -2.7280e-02, -3.8960e-03,  5.6812e-03,\n",
            "          3.5566e-03, -5.2252e-03,  2.1272e-02,  1.0991e-02, -6.6376e-03,\n",
            "          1.2249e-02,  4.7922e-03, -3.6138e-03, -8.1356e-03, -2.8089e-03,\n",
            "          3.3300e-03,  1.6684e-02, -1.7436e-02, -1.1467e-03, -2.4578e-03,\n",
            "          1.2230e-02,  8.5948e-03, -7.2046e-04, -3.4538e-03, -1.9244e-02,\n",
            "         -1.6485e-03,  2.1976e-02,  1.5503e-02, -3.1797e-04,  1.0180e-02,\n",
            "          8.5303e-03, -1.6103e-02,  1.4868e-03, -6.0701e-03, -1.0849e-02,\n",
            "          1.7397e-02,  1.5055e-02, -1.6369e-02,  1.1040e-03, -1.0753e-02,\n",
            "         -4.1771e-03, -6.2505e-03, -2.0385e-03,  2.9294e-03,  1.5790e-03,\n",
            "          8.3643e-03, -6.7133e-03, -4.8510e-03,  6.9113e-03,  9.8084e-03,\n",
            "         -5.5331e-04, -1.1356e-02, -2.0093e-03, -1.5406e-04, -9.5540e-04,\n",
            "          2.6270e-02, -8.4972e-03, -6.2284e-04, -1.0569e-02,  1.5992e-03,\n",
            "         -2.3569e-02,  1.5935e-02,  5.6672e-03,  1.2177e-02, -2.1149e-02,\n",
            "         -2.7388e-02, -1.4374e-02, -6.2587e-03, -5.9894e-03, -1.1412e-02,\n",
            "          1.8742e-02,  4.9487e-03, -5.6326e-03, -1.0632e-03,  1.2264e-02,\n",
            "          8.5276e-03, -3.9805e-03,  2.0568e-02, -8.3128e-03,  6.4579e-03,\n",
            "          1.2927e-02, -1.4407e-02,  8.3794e-03, -5.4061e-04,  1.2553e-02,\n",
            "         -7.5150e-03, -5.2015e-03,  9.9664e-03,  6.3275e-03,  8.4744e-03,\n",
            "         -1.1691e-03, -6.9508e-03, -9.6332e-04, -1.5492e-02, -2.2189e-03,\n",
            "          3.3787e-03,  5.0280e-03,  2.9549e-03,  9.2828e-04,  4.7765e-03,\n",
            "          3.1555e-03, -1.7529e-02, -2.0639e-03,  1.6268e-02, -7.9912e-03,\n",
            "          1.8433e-03,  8.7596e-03,  4.9321e-03,  1.1082e-02,  1.0555e-02,\n",
            "         -1.6911e-03, -6.2136e-03,  8.5398e-03,  5.8390e-03,  1.3652e-03,\n",
            "         -7.5538e-03, -2.2435e-04, -6.8261e-03,  4.9427e-03,  7.9673e-03,\n",
            "          8.1442e-03,  5.5850e-03,  2.9629e-03,  1.1488e-03, -1.1227e-02,\n",
            "         -6.7360e-03, -1.4035e-02,  1.5651e-02, -1.2099e-02, -8.9880e-03,\n",
            "         -1.0055e-03, -1.0659e-03,  8.0971e-03, -5.9774e-03,  8.5595e-03,\n",
            "          2.0393e-02,  1.1718e-02, -1.3158e-04,  1.2494e-02,  7.5866e-03,\n",
            "          1.6439e-02,  1.1770e-02,  5.5186e-03,  1.8072e-02, -8.4626e-03,\n",
            "          1.4859e-02, -4.4461e-03, -6.5696e-03,  1.1811e-02,  7.8499e-03,\n",
            "         -3.1592e-03,  9.2723e-04, -8.6124e-03, -1.6692e-03,  1.1556e-02,\n",
            "          3.7134e-03, -1.3226e-02,  5.8611e-03,  3.7184e-03,  3.2461e-03,\n",
            "         -4.0610e-03, -1.5660e-03, -1.7049e-02, -3.6880e-04, -9.4976e-03,\n",
            "         -9.1202e-03, -4.5646e-03,  2.2151e-02,  6.6617e-03, -1.9954e-02,\n",
            "         -6.9823e-03,  6.1467e-03, -4.6841e-03, -1.0828e-03, -7.9896e-03,\n",
            "         -1.5773e-02, -5.3471e-03,  2.5880e-03,  8.7137e-03,  1.5287e-02,\n",
            "          1.6497e-03,  1.6417e-02,  8.2209e-03, -4.1186e-03,  1.4376e-03,\n",
            "          1.2355e-04,  1.9046e-03,  4.2713e-03,  1.3282e-02,  9.0116e-03,\n",
            "         -1.7868e-02, -4.0997e-04, -8.0441e-03, -2.1865e-02, -3.1874e-03,\n",
            "          1.7793e-02, -8.9083e-04,  3.0451e-04, -8.5681e-03, -5.9518e-03,\n",
            "          8.1174e-03,  1.5051e-02, -6.1810e-03, -8.4053e-03,  1.3830e-02,\n",
            "          1.3400e-02,  1.6472e-02, -6.6404e-03, -1.3628e-02,  1.2781e-02,\n",
            "          2.1924e-03,  1.4915e-02,  2.1685e-03, -8.6995e-03, -5.5474e-03,\n",
            "         -8.7751e-04,  5.1512e-04,  1.7785e-02,  4.5064e-03,  7.2932e-03,\n",
            "         -1.1730e-02,  1.1103e-02, -1.2803e-02, -1.8407e-04,  2.3944e-03,\n",
            "          8.6650e-03,  9.5408e-04,  5.0930e-03,  9.3256e-03, -2.2247e-03,\n",
            "          1.0277e-02, -2.5310e-03, -4.5905e-04,  2.9667e-03,  4.6787e-04,\n",
            "          1.4040e-02, -2.3045e-02,  3.1183e-06,  6.7639e-03,  5.9581e-03,\n",
            "          8.3186e-03,  1.8308e-02, -2.3276e-03,  3.2781e-04, -5.7344e-03,\n",
            "         -1.0030e-02, -8.8161e-03, -9.3416e-03,  6.7653e-03, -4.2932e-03,\n",
            "         -1.0305e-02, -3.7368e-03,  3.5578e-03,  9.6689e-03, -4.0391e-04,\n",
            "         -2.7644e-03, -8.2120e-03,  6.6907e-03,  1.0952e-02, -7.8506e-03,\n",
            "          5.3262e-03,  8.8041e-04,  1.5489e-02, -1.5750e-02,  1.0256e-02,\n",
            "         -3.6477e-03,  3.7881e-03,  1.0808e-02,  1.9235e-02, -7.1602e-03,\n",
            "         -6.5018e-03,  9.0487e-04,  7.6971e-03, -1.8777e-03, -3.7342e-03,\n",
            "         -1.4923e-02, -2.0232e-03, -9.5600e-03,  4.1606e-03, -9.8743e-03,\n",
            "          1.2977e-02,  1.7852e-02,  1.8242e-02, -6.9371e-03,  2.4211e-02,\n",
            "          2.1169e-02,  2.3626e-03,  1.1132e-03,  1.3439e-03,  4.1918e-04,\n",
            "          1.5127e-03,  8.3445e-03,  1.0518e-03, -2.3936e-03, -7.4527e-03,\n",
            "          1.0504e-02, -2.1389e-02, -7.8274e-03, -3.2823e-03, -4.0578e-03,\n",
            "         -5.2134e-03, -5.1620e-03, -1.1042e-02,  2.3842e-02, -2.8036e-03,\n",
            "         -1.9752e-02, -1.0621e-02,  1.5729e-02, -4.7306e-03, -1.1472e-02,\n",
            "         -4.5405e-03, -1.8511e-04, -1.5929e-03, -1.3044e-02,  2.8489e-03,\n",
            "         -6.0452e-03, -2.3317e-03,  1.0988e-02, -3.6564e-04,  5.3358e-03,\n",
            "         -2.1143e-03,  6.1095e-03,  1.0488e-03, -6.1048e-04, -1.8802e-03,\n",
            "          1.1768e-02,  2.1721e-04,  3.5147e-03,  6.7570e-03,  6.2087e-03,\n",
            "          6.0041e-03,  4.6254e-03, -1.0406e-02, -8.2701e-03, -1.8380e-03,\n",
            "          1.6511e-03,  1.6801e-02,  1.5306e-03,  7.2609e-03, -6.4243e-03,\n",
            "          5.6018e-03, -1.1607e-02, -6.8090e-03,  3.5485e-03,  2.9986e-03,\n",
            "         -2.7754e-03,  2.0668e-02, -5.9631e-03,  7.9390e-04,  1.4452e-03,\n",
            "         -4.7812e-03,  5.2699e-03,  8.2727e-03,  1.0473e-02,  2.0009e-03,\n",
            "         -8.7513e-03, -4.4630e-03, -1.3077e-02, -2.6504e-03, -8.3966e-04,\n",
            "          1.5518e-03, -1.8939e-02, -1.8627e-02, -4.3821e-05, -2.1747e-03,\n",
            "          1.4096e-02,  4.9861e-03, -1.0062e-02, -2.6721e-03,  1.0334e-02,\n",
            "         -2.3908e-03, -2.0853e-03,  1.2335e-03,  3.6953e-08, -4.0035e-04,\n",
            "          2.2538e-02,  3.8887e-03,  1.3148e-02, -3.3673e-03, -5.2919e-03,\n",
            "         -6.7603e-03, -9.0466e-03,  6.8763e-03, -2.7153e-04, -1.3809e-02,\n",
            "          4.7060e-03,  3.9600e-03, -1.1301e-03, -2.9161e-03,  3.8353e-03,\n",
            "          1.5836e-02, -2.8845e-03, -4.3257e-03, -9.5109e-03, -1.1623e-03,\n",
            "          3.9024e-03, -1.2383e-04,  8.6588e-03, -6.6189e-03, -3.4719e-03,\n",
            "          4.2813e-03,  3.8377e-04, -1.0937e-02,  1.2215e-02,  1.4025e-02,\n",
            "         -1.1307e-03,  2.1932e-03, -1.1713e-03,  4.0234e-03,  1.5213e-02,\n",
            "         -8.2827e-03,  6.3621e-03,  1.3711e-02, -3.6113e-03,  1.0772e-02,\n",
            "         -1.0618e-02,  1.2495e-03, -1.3037e-02, -1.0050e-02,  6.0683e-03,\n",
            "         -2.6591e-03,  1.5093e-03, -5.3270e-03, -3.9659e-03,  3.2289e-03,\n",
            "          8.5864e-03,  2.5174e-03,  6.0115e-03,  1.1905e-02,  1.0749e-02,\n",
            "         -6.0847e-03,  7.0071e-03,  1.8376e-03, -8.1354e-03, -2.4499e-02,\n",
            "         -5.6661e-03,  2.5762e-02, -9.0869e-03, -1.5484e-03, -1.4350e-03,\n",
            "         -1.5257e-03,  1.8635e-02, -1.4792e-03,  1.6812e-03, -1.2040e-02,\n",
            "          4.5657e-03, -2.1824e-02, -5.9396e-03,  5.4775e-03, -1.3705e-03,\n",
            "          9.1864e-03,  5.4582e-03,  1.1486e-02, -9.6711e-03,  1.7811e-03,\n",
            "         -2.1679e-03, -5.6952e-03,  2.4220e-03,  6.4811e-03, -4.5955e-04,\n",
            "         -1.4729e-02, -3.3512e-03,  7.2137e-03, -4.1840e-03, -3.9352e-03,\n",
            "          1.8836e-02, -5.0016e-03,  1.0803e-02, -7.1893e-03, -4.9978e-03,\n",
            "          9.9435e-03, -9.2497e-03, -1.7412e-02, -8.3613e-03, -1.6402e-02,\n",
            "         -1.0753e-02,  4.1495e-04,  2.9831e-02, -6.7648e-03, -2.3756e-02,\n",
            "         -1.1404e-03,  2.3296e-03,  1.5690e-03,  9.3441e-03, -4.4036e-03,\n",
            "         -1.4055e-02, -1.2296e-02,  5.9235e-03, -9.4258e-03, -6.0423e-03,\n",
            "         -1.6252e-02,  2.0186e-02, -2.0223e-04,  3.7986e-03,  2.6177e-04,\n",
            "          5.2196e-03, -3.9315e-03,  1.6960e-02,  1.2301e-02, -2.0914e-02,\n",
            "         -4.7771e-03, -8.5589e-03,  2.4387e-02,  1.1563e-02, -1.2528e-02,\n",
            "         -2.0921e-02, -1.6102e-02]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0261,  0.0182, -0.0021,  ..., -0.0040, -0.0045, -0.0233],\n",
            "        [ 0.0035, -0.0050, -0.0111,  ...,  0.0215, -0.0143,  0.0021],\n",
            "        [-0.0079, -0.0149,  0.0090,  ..., -0.0240,  0.0025, -0.0151],\n",
            "        ...,\n",
            "        [ 0.0044,  0.0176,  0.0063,  ..., -0.0021, -0.0076,  0.0037],\n",
            "        [ 0.0169,  0.0050,  0.0062,  ...,  0.0058,  0.0116, -0.0015],\n",
            "        [-0.0049, -0.0130, -0.0005,  ..., -0.0035, -0.0065, -0.0094]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-1.3346e-02,  4.9142e-03,  2.4095e-03,  ...,  1.2706e-02,\n",
            "          5.9349e-03,  8.2871e-03],\n",
            "        [-1.1347e-02,  3.5384e-03,  8.5065e-03,  ...,  1.1713e-02,\n",
            "          1.5137e-03,  1.5244e-02],\n",
            "        [ 1.0767e-03, -4.0444e-03, -1.8080e-03,  ..., -1.1232e-02,\n",
            "         -1.9007e-02, -7.0704e-03],\n",
            "        ...,\n",
            "        [-3.6899e-03,  2.1554e-03, -6.1473e-03,  ..., -1.9017e-02,\n",
            "         -3.5464e-03, -9.3668e-03],\n",
            "        [-2.8604e-03,  6.2260e-04,  6.6550e-03,  ...,  9.1159e-03,\n",
            "          6.5451e-03,  4.3001e-06],\n",
            "        [-1.9700e-05,  3.6454e-03, -1.4572e-02,  ..., -2.7933e-03,\n",
            "         -5.5957e-03,  7.7887e-03]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0040,  0.0094, -0.0005,  ...,  0.0002,  0.0092, -0.0021],\n",
            "        [ 0.0044,  0.0011,  0.0074,  ..., -0.0008, -0.0139,  0.0010],\n",
            "        [-0.0018,  0.0249, -0.0134,  ..., -0.0046, -0.0044,  0.0152],\n",
            "        ...,\n",
            "        [ 0.0155,  0.0007,  0.0006,  ...,  0.0099,  0.0115,  0.0016],\n",
            "        [ 0.0012,  0.0064,  0.0151,  ..., -0.0061,  0.0057,  0.0079],\n",
            "        [-0.0101, -0.0060, -0.0121,  ...,  0.0006, -0.0049,  0.0019]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0070,  0.0119,  0.0124,  ..., -0.0077, -0.0014,  0.0215],\n",
            "        [-0.0144, -0.0022,  0.0059,  ..., -0.0221,  0.0003, -0.0100],\n",
            "        [ 0.0126,  0.0094, -0.0193,  ..., -0.0031,  0.0006,  0.0002],\n",
            "        ...,\n",
            "        [-0.0137,  0.0005, -0.0100,  ...,  0.0001,  0.0087, -0.0015],\n",
            "        [-0.0006,  0.0119,  0.0092,  ...,  0.0132,  0.0003,  0.0074],\n",
            "        [ 0.0068, -0.0085, -0.0112,  ...,  0.0055,  0.0115,  0.0050]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       requires_grad=True)\n",
            "The model has 7,046,150 trainable parameters 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
      ],
      "metadata": {
        "id": "RX4jfWbZvd_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train)):\n",
        "  lista = train[i]['de_ids']\n",
        "  print(lista)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6prjCAn_07o",
        "outputId": "403cf308-311f-4b25-f5dc-6aab09aa6a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2, 27,  4,  3])\n",
            "tensor([ 2, 99,  5,  3])\n",
            "tensor([2, 0, 0, 5, 3])\n",
            "tensor([  2, 146,   5,   3])\n",
            "tensor([  2, 146,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([  2, 240, 112,   5,   3])\n",
            "tensor([  2, 132,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 25,  0,  5,  3])\n",
            "tensor([ 2,  0, 12,  5,  3])\n",
            "tensor([  2, 178,  50,   5,   3])\n",
            "tensor([  2, 194,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 88,  5,  3])\n",
            "tensor([ 2, 88,  4,  3])\n",
            "tensor([ 2, 97, 35,  4,  3])\n",
            "tensor([  2, 247,   7,   5,   3])\n",
            "tensor([  2, 279,   7,   4,   3])\n",
            "tensor([  2,  17, 185,   4,   3])\n",
            "tensor([ 2, 99,  5,  3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 99,  5,  3])\n",
            "tensor([  2, 119,  12,   5,   3])\n",
            "tensor([  2, 264,   5,   3])\n",
            "tensor([  2,   6, 282,  18,   4,   3])\n",
            "tensor([  2,   6,  14,  18, 178,   4,   3])\n",
            "tensor([  2,   6, 110,   4,   3])\n",
            "tensor([  2,   6, 179,   4,   3])\n",
            "tensor([  2, 186,   4,   3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([  2,   6, 226,  37,   5,   3])\n",
            "tensor([ 2,  6, 14, 37,  5,  3])\n",
            "tensor([ 2,  6, 14, 37,  4,  3])\n",
            "tensor([  2,   0,  53, 251,   5,   3])\n",
            "tensor([  2, 130,  12,   4,   3])\n",
            "tensor([  2, 132,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 63, 13,  3])\n",
            "tensor([ 2, 66, 18,  5,  3])\n",
            "tensor([  2, 210,  18,   5,   3])\n",
            "tensor([  2, 209,  10,  18,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2,  0, 49,  5,  3])\n",
            "tensor([  2,   0, 294,   5,   3])\n",
            "tensor([  2, 101,   7,   4,   3])\n",
            "tensor([  2, 101, 205,   5,   3])\n",
            "tensor([  2, 101,  19,   4,   3])\n",
            "tensor([  2, 101,  19,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([2, 0, 0, 5, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 27, 51,  5,  3])\n",
            "tensor([  2, 177,   5,   3])\n",
            "tensor([  2,   6, 226,  49,   5,   3])\n",
            "tensor([  2, 186,   5,   3])\n",
            "tensor([ 2,  0, 13,  3])\n",
            "tensor([  2, 177,  13,   3])\n",
            "tensor([ 2, 95, 13,  3])\n",
            "tensor([  2,  20, 110,   4,   3])\n",
            "tensor([ 2, 20,  0,  4,  3])\n",
            "tensor([ 2, 17, 74,  5,  3])\n",
            "tensor([  2,   0, 158,   5,   3])\n",
            "tensor([  2, 128,  18,   5,   3])\n",
            "tensor([  2,  60,  18,  43, 126,   0,   5,   3])\n",
            "tensor([  2, 281,  18,   5,   3])\n",
            "tensor([ 2, 15, 11,  7,  0,  4,  3])\n",
            "tensor([ 2,  6, 64,  4,  3])\n",
            "tensor([ 2,  6, 64, 59,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([  2,   6,  14, 217,   4,   3])\n",
            "tensor([ 2,  6, 14, 45,  4,  3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([  2,   6, 258,   4,   3])\n",
            "tensor([  2,   6, 276,   4,   3])\n",
            "tensor([  2,   6,  14, 223,   4,   3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([  2,   6, 184,   4,   3])\n",
            "tensor([  2,   6,  14, 225,   4,   3])\n",
            "tensor([  2,   6,   8,   0,   0, 117,   4,   3])\n",
            "tensor([2, 6, 8, 0, 3])\n",
            "tensor([ 2, 15, 68, 29,  4,  3])\n",
            "tensor([ 2,  7, 32, 15, 29,  4,  3])\n",
            "tensor([  2,   6,   8, 114,   4,   3])\n",
            "tensor([ 2,  6,  8, 19,  4,  3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2,  0, 25,  4,  3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 16, 71, 21, 43,  0,  5,  3])\n",
            "tensor([ 2, 16,  0, 49, 94, 21,  5,  3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 43,  0,  0,  5,  3])\n",
            "tensor([ 2,  0, 13,  3])\n",
            "tensor([ 2,  0, 13,  3])\n",
            "tensor([ 2,  0, 96, 13,  3])\n",
            "tensor([  2, 195,   5,   3])\n",
            "tensor([  2, 195,   5,   3])\n",
            "tensor([  2, 180,  49,   5,   3])\n",
            "tensor([  2,  34, 283,   7,   4,   3])\n",
            "tensor([ 2, 34, 69, 37,  4,  3])\n",
            "tensor([ 2,  0,  6, 13,  3])\n",
            "tensor([  2,  11,  74,  15,   0,  43, 154,  13,   3])\n",
            "tensor([ 2, 66,  9,  5,  3])\n",
            "tensor([  2, 209,  10,   9,   5,   3])\n",
            "tensor([  2, 210,   9,   5,   3])\n",
            "tensor([ 2, 66,  9,  4,  3])\n",
            "tensor([  2, 203,   5,   3])\n",
            "tensor([  2, 130,  12,   5,   3])\n",
            "tensor([ 2, 44, 21,  0,  5,  3])\n",
            "tensor([ 2, 44,  0,  5,  3])\n",
            "tensor([  2,  44, 152,   5,   3])\n",
            "tensor([  2,  44, 152,   5,   3])\n",
            "tensor([  2, 165,  10, 152,   5,   3])\n",
            "tensor([ 2, 27, 30,  5,  3])\n",
            "tensor([ 2, 70, 23,  5,  3])\n",
            "tensor([ 2, 84,  5,  3])\n",
            "tensor([ 2, 82,  5,  3])\n",
            "tensor([ 2, 17, 12, 36,  5,  3])\n",
            "tensor([ 2, 61, 73,  5,  3])\n",
            "tensor([ 2, 17, 12, 86, 62,  5,  3])\n",
            "tensor([ 2, 85, 12,  5,  3])\n",
            "tensor([ 2, 83, 12,  5,  3])\n",
            "tensor([ 2, 80, 12,  5,  3])\n",
            "tensor([ 2, 91, 23,  5,  3])\n",
            "tensor([ 2, 75, 12,  5,  3])\n",
            "tensor([ 2, 17, 92, 65,  5,  3])\n",
            "tensor([ 2, 78, 23,  5,  3])\n",
            "tensor([ 2, 17, 41, 76,  5,  3])\n",
            "tensor([ 2, 39, 12, 30,  5,  3])\n",
            "tensor([ 2, 39, 12, 36,  5,  3])\n",
            "tensor([2, 0, 7, 5, 3])\n",
            "tensor([2, 0, 7, 5, 3])\n",
            "tensor([ 2,  0, 10,  7,  5,  3])\n",
            "tensor([2, 0, 7, 5, 3])\n",
            "tensor([  2, 161,  18,  35,   4,   3])\n",
            "tensor([  2,  33, 141,   4,   3])\n",
            "tensor([  2, 141,   5,   3])\n",
            "tensor([ 2, 33,  5,  3])\n",
            "tensor([ 2, 71,  5,  3])\n",
            "tensor([  2,  17, 164,   5,   3])\n",
            "tensor([  2,   0, 164,   5,   3])\n",
            "tensor([  2,  33, 164,   5,   3])\n",
            "tensor([  2, 107,   7, 131,   5,   3])\n",
            "tensor([  2, 131, 145,   5,   3])\n",
            "tensor([  2, 131, 145,   5,   3])\n",
            "tensor([2, 0, 7, 0, 5, 3])\n",
            "tensor([  2, 143,   9,   4,   3])\n",
            "tensor([  2, 111,   5,   3])\n",
            "tensor([  2,  32, 111,   5,   3])\n",
            "tensor([  2,  27, 111,   4,   3])\n",
            "tensor([  2,  32, 111,   5,   3])\n",
            "tensor([ 2, 27, 30,  5,  3])\n",
            "tensor([ 2, 70, 23,  5,  3])\n",
            "tensor([ 2, 84,  5,  3])\n",
            "tensor([ 2, 82,  5,  3])\n",
            "tensor([ 2, 17, 12, 36,  5,  3])\n",
            "tensor([ 2, 61, 73,  5,  3])\n",
            "tensor([ 2, 17, 12, 86, 62,  5,  3])\n",
            "tensor([ 2, 85, 12,  5,  3])\n",
            "tensor([ 2, 83, 12,  5,  3])\n",
            "tensor([ 2, 80, 12,  5,  3])\n",
            "tensor([ 2, 91, 23,  5,  3])\n",
            "tensor([ 2, 75, 12,  5,  3])\n",
            "tensor([ 2, 17, 92, 65,  5,  3])\n",
            "tensor([ 2, 78, 23,  5,  3])\n",
            "tensor([ 2, 17, 41, 76,  5,  3])\n",
            "tensor([ 2, 39, 12, 30,  5,  3])\n",
            "tensor([ 2, 39, 12, 36,  5,  3])\n",
            "tensor([ 2, 31, 10, 30,  5,  3])\n",
            "tensor([ 2, 27, 30,  5,  3])\n",
            "tensor([  2, 175,  12,   5,   3])\n",
            "tensor([ 2, 70, 23,  5,  3])\n",
            "tensor([ 2, 84,  5,  3])\n",
            "tensor([ 2, 82,  5,  3])\n",
            "tensor([ 2, 17, 12, 36,  5,  3])\n",
            "tensor([ 2, 61, 73,  5,  3])\n",
            "tensor([ 2, 17, 12, 86, 62,  5,  3])\n",
            "tensor([ 2, 85, 12,  5,  3])\n",
            "tensor([ 2, 83, 12,  5,  3])\n",
            "tensor([ 2, 80, 12,  5,  3])\n",
            "tensor([ 2, 91, 23,  5,  3])\n",
            "tensor([ 2, 75, 12,  5,  3])\n",
            "tensor([ 2, 17, 92, 65,  5,  3])\n",
            "tensor([ 2, 78, 23,  5,  3])\n",
            "tensor([ 2, 17, 41, 76,  5,  3])\n",
            "tensor([ 2, 39, 12, 30,  5,  3])\n",
            "tensor([ 2, 39, 12, 36,  5,  3])\n",
            "tensor([ 2, 31, 10, 30,  4,  3])\n",
            "tensor([  2,  27, 108, 232,   4,   3])\n",
            "tensor([  2,  27, 140,   4,   3])\n",
            "tensor([  2,  19, 292,   5,   3])\n",
            "tensor([  2,   0, 294,   5,   3])\n",
            "tensor([  2, 278,   5,   3])\n",
            "tensor([  2,  19, 292,   4,   3])\n",
            "tensor([ 2, 21,  0,  5,  3])\n",
            "tensor([ 2, 88,  5,  3])\n",
            "tensor([  2,  20, 102,   4,   3])\n",
            "tensor([  2,  20,  11, 134,   4,   3])\n",
            "tensor([  2,  20, 256,   4,   3])\n",
            "tensor([ 2, 20,  0,  4,  3])\n",
            "tensor([  2, 142,  15,   4,   3])\n",
            "tensor([  2, 142,  22,   5,   3])\n",
            "tensor([  2, 234,  22,   5,   3])\n",
            "tensor([  2, 233,  10,  22,   5,   3])\n",
            "tensor([ 2, 99, 53,  9,  5,  3])\n",
            "tensor([  2, 262,   9,   5,   3])\n",
            "tensor([2, 0, 9, 5, 3])\n",
            "tensor([ 2,  0, 10,  9,  5,  3])\n",
            "tensor([ 2, 21,  0,  5,  3])\n",
            "tensor([ 2, 88,  5,  3])\n",
            "tensor([  2,  79, 124,   5,   3])\n",
            "tensor([  2, 194,  79,   5,   3])\n",
            "tensor([  2, 124,  10,  79,   5,   3])\n",
            "tensor([ 2,  0, 79,  5,  3])\n",
            "tensor([  2, 182,  10, 105,   5,   3])\n",
            "tensor([ 2, 16, 11,  0,  0,  5,  3])\n",
            "tensor([  2, 281,   9,   5,   3])\n",
            "tensor([ 2,  0, 10,  9,  5,  3])\n",
            "tensor([2, 0, 9, 5, 3])\n",
            "tensor([2, 0, 9, 5, 3])\n",
            "tensor([ 2,  0, 10,  9,  5,  3])\n",
            "tensor([  2, 128,   9,   5,   3])\n",
            "tensor([ 2,  6,  8, 95,  4,  3])\n",
            "tensor([  2,   6, 184,   4,   3])\n",
            "tensor([  2,   6,  14, 225,   4,   3])\n",
            "tensor([2, 6, 0, 5, 3])\n",
            "tensor([2, 6, 8, 0, 5, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([ 2,  6, 67,  4,  3])\n",
            "tensor([  2,   6,   8, 163,   4,   3])\n",
            "tensor([  2,   6,   8, 206,   4,   3])\n",
            "tensor([  2,   6,   8, 196,   4,   3])\n",
            "tensor([  2,   6,  90, 135,   5,   3])\n",
            "tensor([ 2, 15, 11, 57,  4,  3])\n",
            "tensor([  2,   6,   8, 104,   5,   3])\n",
            "tensor([  2,   6,   8, 259,   4,   3])\n",
            "tensor([  2,   6,   8, 176,   4,   3])\n",
            "tensor([  2,   6,   8, 109,   4,   3])\n",
            "tensor([  2,   6,   8, 117,   4,   3])\n",
            "tensor([  2,   6,   8, 171,   4,   3])\n",
            "tensor([  2,   6,   8, 268,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   7,  11,  43, 154,   4,   3])\n",
            "tensor([ 2,  6,  8, 49,  4,  3])\n",
            "tensor([ 2,  6,  8, 49,  4,  3])\n",
            "tensor([ 2, 33, 74,  4,  3])\n",
            "tensor([ 2, 71, 74,  4,  3])\n",
            "tensor([  2, 120,   7,   5,   3])\n",
            "tensor([  2, 120,  42,   5,   3])\n",
            "tensor([  2, 120,  10,   5,   3])\n",
            "tensor([  2, 121,  10,  42,   5,   3])\n",
            "tensor([  2, 121,  10,  10,   5,   3])\n",
            "tensor([  2, 121,  10,   7,   5,   3])\n",
            "tensor([  2, 122,  42,   5,   3])\n",
            "tensor([  2, 122,  10,   5,   3])\n",
            "tensor([  2, 122,   7,   5,   3])\n",
            "tensor([  2, 280,   7,   5,   3])\n",
            "tensor([  2, 241,  18,   4,   3])\n",
            "tensor([ 2, 72, 12, 59,  5,  3])\n",
            "tensor([  2, 235,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([  2,  72,  12, 153,   5,   3])\n",
            "tensor([  2, 148,  50, 153,   5,   3])\n",
            "tensor([  2, 147,  10,  40, 153,   5,   3])\n",
            "tensor([  2, 148,  50,  59,   5,   3])\n",
            "tensor([  2, 147,  10,  40,  59,   5,   3])\n",
            "tensor([  2, 263,   7,  23,   4,   3])\n",
            "tensor([ 2,  0, 10, 23,  4,  3])\n",
            "tensor([  2, 263,  42,  23,   4,   3])\n",
            "tensor([  2,   6, 187,   4,   3])\n",
            "tensor([  2,  15, 187,   4,   3])\n",
            "tensor([2, 0, 7, 5, 3])\n",
            "tensor([2, 0, 7, 5, 3])\n",
            "tensor([ 2,  0, 10,  7,  5,  3])\n",
            "tensor([ 2, 17, 19,  5,  3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([  2,  61, 127,   4,   3])\n",
            "tensor([  2, 128,   0,   4,   3])\n",
            "tensor([  2, 162,   0,   0,   5,   0,   3])\n",
            "tensor([  2, 278,   5,   3])\n",
            "tensor([ 2, 34,  0, 22,  4,  3])\n",
            "tensor([ 2,  0, 15,  5,  3])\n",
            "tensor([  2,   0, 100,   4,   3])\n",
            "tensor([  2, 138,  49,   0,   5,   3])\n",
            "tensor([2, 0, 0, 5, 3])\n",
            "tensor([ 2,  0, 19,  4,  3])\n",
            "tensor([ 2, 60,  7,  4,  3])\n",
            "tensor([2, 0, 7, 4, 3])\n",
            "tensor([  2, 250,  10,   7,   4,   3])\n",
            "tensor([  2, 162,   7,  15,   4,   3])\n",
            "tensor([ 2,  0, 15,  4,  3])\n",
            "tensor([  2,   9, 191,   4,   3])\n",
            "tensor([  2,   9,  26, 215,   4,   3])\n",
            "tensor([  2,  52, 282,  40,   4,   3])\n",
            "tensor([  2,  52,  26,  40, 178,   4,   3])\n",
            "tensor([  2,   9, 110,   4,   3])\n",
            "tensor([  2,   9,  11, 219,   4,   3])\n",
            "tensor([ 2,  9, 26, 37,  4,  3])\n",
            "tensor([ 2, 88, 38,  5,  3])\n",
            "tensor([  2, 182,  10,  38,   5,   3])\n",
            "tensor([ 2,  0, 38,  5,  3])\n",
            "tensor([  2, 114,  19,   5,   3])\n",
            "tensor([  2, 287,  10,  19,   5,   3])\n",
            "tensor([  2, 114,  19,   5,   3])\n",
            "tensor([  2, 287,  10,  19,   5,   3])\n",
            "tensor([  2, 183,  46,  41, 237,   4,   3])\n",
            "tensor([  2, 183,  12,   4,   3])\n",
            "tensor([  2, 183,  46,  16,   0,   4,   3])\n",
            "tensor([ 2, 34, 69, 45,  4,  3])\n",
            "tensor([ 2, 34,  0,  4,  3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([  2,  28,  26, 215,  13,   3])\n",
            "tensor([  2,  28, 191,  13,   3])\n",
            "tensor([  2,  28, 110,  13,   3])\n",
            "tensor([  2,  28,  11, 219,  13,   3])\n",
            "tensor([ 2, 28, 26, 37, 13,  3])\n",
            "tensor([ 2, 54,  0,  4,  3])\n",
            "tensor([  2,  10, 242,   4,   3])\n",
            "tensor([  2,  54, 139,  37,   4,   3])\n",
            "tensor([  2,  54, 139,  37,   4,   3])\n",
            "tensor([2, 0, 0, 5, 3])\n",
            "tensor([  2,   8,   6, 196,  13,   3])\n",
            "tensor([ 2, 66, 10,  4,  3])\n",
            "tensor([ 2, 33, 21,  0,  5,  3])\n",
            "tensor([  2,  44,  55, 248,   5,   3])\n",
            "tensor([ 2, 44,  0,  5,  3])\n",
            "tensor([  2,  44, 170,   5,   3])\n",
            "tensor([  2, 165,  10, 170,   5,   3])\n",
            "tensor([  2, 270, 170,   5,   3])\n",
            "tensor([  2,   0,  10,  40, 105,   4,   3])\n",
            "tensor([  2, 204,  12, 105,   4,   3])\n",
            "tensor([  2,   0,  50, 105,   4,   3])\n",
            "tensor([  2,  44, 149,   4,   3])\n",
            "tensor([  2, 270, 149,   4,   3])\n",
            "tensor([  2, 165,  10, 149,   4,   3])\n",
            "tensor([ 2, 44,  0,  4,  3])\n",
            "tensor([  2, 161,   9,  35,   5,   3])\n",
            "tensor([ 2,  0,  9, 35,  5,  3])\n",
            "tensor([  2, 257,  10,   9,  35,   5,   3])\n",
            "tensor([ 2,  0,  9, 35,  5,  3])\n",
            "tensor([ 2, 47,  6, 31, 13,  3])\n",
            "tensor([ 2, 97, 18,  5,  3])\n",
            "tensor([  2, 201,  10,  18,   5,   3])\n",
            "tensor([  2, 202,  18,   5,   3])\n",
            "tensor([  2, 240,   0,   5,   3])\n",
            "tensor([ 2,  0, 12, 23,  5,  3])\n",
            "tensor([  2,  72, 238, 230,  35,   4,   3])\n",
            "tensor([  2, 147,  10, 238, 230,  35,   4,   3])\n",
            "tensor([ 2, 27, 21,  4,  3])\n",
            "tensor([  2, 199, 185,   4,   3])\n",
            "tensor([2, 0, 9, 4, 3])\n",
            "tensor([2, 0, 9, 4, 3])\n",
            "tensor([ 2,  0, 10,  9,  4,  3])\n",
            "tensor([ 2,  0, 10, 16,  4,  3])\n",
            "tensor([ 2,  0, 16,  4,  3])\n",
            "tensor([ 2,  0, 16,  4,  3])\n",
            "tensor([ 2,  0, 10, 16,  4,  3])\n",
            "tensor([ 2, 27, 30,  5,  3])\n",
            "tensor([  2, 175,  12,   5,   3])\n",
            "tensor([ 2, 70, 23,  5,  3])\n",
            "tensor([ 2, 84,  5,  3])\n",
            "tensor([ 2, 82,  5,  3])\n",
            "tensor([ 2, 17, 12, 36,  5,  3])\n",
            "tensor([ 2, 61, 73,  5,  3])\n",
            "tensor([ 2, 17, 12, 86, 62,  5,  3])\n",
            "tensor([ 2, 85, 12,  5,  3])\n",
            "tensor([ 2, 83, 12,  5,  3])\n",
            "tensor([ 2, 80, 12,  5,  3])\n",
            "tensor([ 2, 91, 23,  5,  3])\n",
            "tensor([ 2, 75, 12,  5,  3])\n",
            "tensor([ 2, 17, 92, 65,  5,  3])\n",
            "tensor([ 2, 78, 23,  5,  3])\n",
            "tensor([ 2, 17, 41, 76,  5,  3])\n",
            "tensor([ 2, 39, 12, 30,  5,  3])\n",
            "tensor([ 2, 39, 12, 36,  5,  3])\n",
            "tensor([  2, 112,   5,   3])\n",
            "tensor([  2, 235,   5,   3])\n",
            "tensor([ 2, 43,  0,  5,  3])\n",
            "tensor([  2,  33, 112,   4,   3])\n",
            "tensor([  2, 144,  10, 112,   4,   3])\n",
            "tensor([ 2, 27, 30,  5,  3])\n",
            "tensor([  2, 175,  12,   5,   3])\n",
            "tensor([ 2, 70, 23,  5,  3])\n",
            "tensor([ 2, 84,  5,  3])\n",
            "tensor([ 2, 82,  5,  3])\n",
            "tensor([ 2, 17, 12, 36,  5,  3])\n",
            "tensor([ 2, 61, 73,  5,  3])\n",
            "tensor([ 2, 17, 12, 86, 62,  5,  3])\n",
            "tensor([ 2, 85, 12,  5,  3])\n",
            "tensor([ 2, 83, 12,  5,  3])\n",
            "tensor([ 2, 80, 12,  5,  3])\n",
            "tensor([ 2, 91, 23,  5,  3])\n",
            "tensor([ 2, 75, 12,  5,  3])\n",
            "tensor([ 2, 17, 92, 65,  5,  3])\n",
            "tensor([ 2, 78, 23,  5,  3])\n",
            "tensor([ 2, 17, 41, 76,  5,  3])\n",
            "tensor([ 2, 39, 12, 30,  5,  3])\n",
            "tensor([ 2, 39, 12, 36,  5,  3])\n",
            "tensor([ 2,  0, 12,  5,  3])\n",
            "tensor([ 2, 51, 38,  0,  5,  3])\n",
            "tensor([  2, 252,  25,   5,   3])\n",
            "tensor([  2,  17, 185,   5,   3])\n",
            "tensor([ 2, 27, 93, 59,  5,  3])\n",
            "tensor([  2, 143,   9,   4,   3])\n",
            "tensor([ 2,  0, 42, 46,  5,  3])\n",
            "tensor([  2, 286,   0,   5,   3])\n",
            "tensor([  2, 286, 169,   5,   3])\n",
            "tensor([  2,   0, 267,   5,   3])\n",
            "tensor([ 2, 20,  0,  4,  3])\n",
            "tensor([ 2, 20,  0,  7,  4,  3])\n",
            "tensor([  2,  20,  26,   7, 181,   4,   3])\n",
            "tensor([  2,  20, 181,   7,   4,   3])\n",
            "tensor([ 2, 20, 11,  9,  4,  3])\n",
            "tensor([  2, 142,   9,   5,   3])\n",
            "tensor([  2, 234,   9,   5,   3])\n",
            "tensor([  2, 233,  10,   9,   5,   3])\n",
            "tensor([  2,  89,  11,  16,  21, 277,   5,   3])\n",
            "tensor([  2,  48, 277,   5,   3])\n",
            "tensor([ 2, 48,  0,  5,  3])\n",
            "tensor([ 2, 48,  0, 13,  3])\n",
            "tensor([  2,  48, 267,   5,   3])\n",
            "tensor([ 2, 48,  0,  5,  3])\n",
            "tensor([ 2, 48,  0,  5,  3])\n",
            "tensor([  2,   0,  15, 126,  98,   4,   3])\n",
            "tensor([  2, 172,  10,  15, 126,  98,   4,   3])\n",
            "tensor([  2, 119,  12,   5,   3])\n",
            "tensor([  2, 119,  12,   4,   3])\n",
            "tensor([ 2, 17, 59,  5,  3])\n",
            "tensor([ 2,  6, 47, 31,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([  2,   6,  14,   7, 221,   4,   3])\n",
            "tensor([  2,   6, 227, 218,   4,   3])\n",
            "tensor([  2,   6, 103,   0,   4,   3])\n",
            "tensor([  2,   6, 103,   0,   4,   3])\n",
            "tensor([  2,   6, 103,   0,  41,   0,   4,   3])\n",
            "tensor([  2,   6, 179,   4,   3])\n",
            "tensor([  2,   6,  14,   7, 177,   4,   3])\n",
            "tensor([ 2,  6, 14,  7,  0,  4,  3])\n",
            "tensor([  2,   6, 227,   4,   3])\n",
            "tensor([  2,   6, 231,   7,   4,   3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6,  0, 35,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6,  0, 18,  4,  3])\n",
            "tensor([2, 6, 0, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([  2,   6, 254,  18,   4,   3])\n",
            "tensor([ 2,  6, 14, 18,  0,  4,  3])\n",
            "tensor([  2,   6, 246,   4,   3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([  2,   6,  24,   7, 283,   4,   3])\n",
            "tensor([  2,   6,   8, 197,   4,   3])\n",
            "tensor([  2,   6,   8, 291,  93,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,  14, 129,   0,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,  14,  25, 172,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,   8, 220,   4,   3])\n",
            "tensor([ 2, 15, 68, 29,  4,  3])\n",
            "tensor([ 2, 15, 32,  7, 29,  4,  3])\n",
            "tensor([ 2,  7, 32, 15, 29,  4,  3])\n",
            "tensor([  2,   6,   8, 211,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6, 247,  74,   4,   3])\n",
            "tensor([ 2, 15, 68, 29,  4,  3])\n",
            "tensor([ 2,  6,  8, 58,  4,  3])\n",
            "tensor([  2,   6,   8,  25, 232,   4,   3])\n",
            "tensor([  2,   6, 103,  25, 113,   4,   3])\n",
            "tensor([ 2,  6, 14, 18,  0,  4,  3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 0, 4, 3])\n",
            "tensor([ 2,  7, 32, 15, 29,  4,  3])\n",
            "tensor([  2,   6,   8, 255,   4,   3])\n",
            "tensor([  2,   6,   8, 167,   4,   3])\n",
            "tensor([  2,   6,   8, 104,   5,   3])\n",
            "tensor([  2,   6,   8, 167,   4,   3])\n",
            "tensor([  2,   6,   8, 137,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6, 269, 163, 190,   4,   3])\n",
            "tensor([  2,   6,   8, 265,   4,   3])\n",
            "tensor([ 2, 15, 32,  7, 29,  4,  3])\n",
            "tensor([ 2,  7, 32, 15, 29,  4,  3])\n",
            "tensor([ 2, 16,  0,  4,  3])\n",
            "tensor([  2,   7, 173,   0,   4,   3])\n",
            "tensor([2, 7, 0, 4, 3])\n",
            "tensor([2, 7, 0, 4, 3])\n",
            "tensor([  2,   7, 212,   4,   3])\n",
            "tensor([ 2,  7, 11,  9,  4,  3])\n",
            "tensor([  2,  10,  11, 137,   4,   3])\n",
            "tensor([ 2,  7, 11,  0,  4,  3])\n",
            "tensor([ 2,  7, 11,  0,  4,  3])\n",
            "tensor([ 2,  7, 11, 57,  4,  3])\n",
            "tensor([ 2, 10, 11, 57,  4,  3])\n",
            "tensor([ 2, 20, 11, 57,  4,  3])\n",
            "tensor([  2,   7,  11, 109,   4,   3])\n",
            "tensor([  2,  16,  11, 160,   4,   3])\n",
            "tensor([  2,   7,  11, 171,   4,   3])\n",
            "tensor([ 2, 16, 11,  0,  4,  3])\n",
            "tensor([2, 0, 0, 5, 3])\n",
            "tensor([  2,  33,  21, 141,   4,   3])\n",
            "tensor([2, 0, 0, 4, 3])\n",
            "tensor([  2, 280,  52,   5,   3])\n",
            "tensor([ 2,  0, 52,  5,  3])\n",
            "tensor([ 2,  0, 10, 52,  5,  3])\n",
            "tensor([2, 0, 9, 5, 3])\n",
            "tensor([ 2,  0, 10,  9,  5,  3])\n",
            "tensor([  2, 241,   9,   5,   3])\n",
            "tensor([ 2, 27, 30,  5,  3])\n",
            "tensor([ 2, 31, 10, 30,  4,  3])\n",
            "tensor([  2, 106,  22, 116,   4,   3])\n",
            "tensor([  2, 145,  10,  22, 116,   4,   3])\n",
            "tensor([  2, 106,  22,  31,   5,   3])\n",
            "tensor([ 2, 19, 68,  5,  3])\n",
            "tensor([ 2, 31, 34,  5,  3])\n",
            "tensor([  2, 107,  22,  31,   4,   3])\n",
            "tensor([  2, 106,  22, 245,   4,   3])\n",
            "tensor([  2, 107,  22, 245,   4,   3])\n",
            "tensor([ 2, 19, 53, 19,  5,  3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2,  0, 18,  4,  3])\n",
            "tensor([ 2,  0,  6, 31, 13,  3])\n",
            "tensor([2, 0, 9, 5, 3])\n",
            "tensor([2, 0, 9, 5, 3])\n",
            "tensor([ 2,  0, 10,  9,  5,  3])\n",
            "tensor([  2,  10, 102,   4,   3])\n",
            "tensor([  2,  10,  11, 134,   4,   3])\n",
            "tensor([  2,  10, 256,   4,   3])\n",
            "tensor([  2, 166,  12,   5,   3])\n",
            "tensor([  2, 272,  10,  40,   5,   3])\n",
            "tensor([  2, 166,  12,   5,   3])\n",
            "tensor([2, 0, 0, 5, 3])\n",
            "tensor([ 2, 72, 38,  0,  0, 25,  5,  3])\n",
            "tensor([ 2, 79, 10, 19,  5,  3])\n",
            "tensor([ 2,  0, 19,  5,  3])\n",
            "tensor([ 2,  0, 19,  5,  3])\n",
            "tensor([ 2,  0, 19,  4,  3])\n",
            "tensor([ 2,  0,  9, 19,  5,  3])\n",
            "tensor([  2, 228,  10,   9,  19,   5,   3])\n",
            "tensor([  2, 229,   9,  19,   5,   3])\n",
            "tensor([ 2, 60,  9,  4,  3])\n",
            "tensor([  2, 156,   7,  38,   4,   3])\n",
            "tensor([  2, 162,   7,   9,   4,   3])\n",
            "tensor([ 2,  0, 10,  7,  9,  4,  3])\n",
            "tensor([2, 0, 7, 9, 4, 3])\n",
            "tensor([  2,   0,  10,   9, 125,   4,   3])\n",
            "tensor([2, 0, 7, 9, 4, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 10, 69, 37,  4,  3])\n",
            "tensor([  2,   9, 102,   4,   3])\n",
            "tensor([  2,   9,  11, 216,   4,   3])\n",
            "tensor([  2,   9,  11, 224,   4,   3])\n",
            "tensor([2, 9, 0, 4, 3])\n",
            "tensor([ 2,  9, 64,  4,  3])\n",
            "tensor([ 2,  9, 11, 98,  4,  3])\n",
            "tensor([  2,   9, 115,   7,   4,   3])\n",
            "tensor([ 2,  9, 26,  7,  0,  4,  3])\n",
            "tensor([  2,   9, 115,   0,   4,   3])\n",
            "tensor([  2,   9,  11, 134,   4,   3])\n",
            "tensor([  2,   9, 136,   4,   3])\n",
            "tensor([  2,   9,  26, 217,   4,   3])\n",
            "tensor([2, 9, 0, 4, 3])\n",
            "tensor([2, 9, 0, 4, 3])\n",
            "tensor([ 2,  9, 26, 45,  4,  3])\n",
            "tensor([ 2,  9, 26,  0,  4,  3])\n",
            "tensor([  2,   9,  26, 188,   4,   3])\n",
            "tensor([  2,   9, 258,   4,   3])\n",
            "tensor([  2,  52, 276,   4,   3])\n",
            "tensor([  2,  52,  26, 223,   4,   3])\n",
            "tensor([  2,   9, 266,   4,   3])\n",
            "tensor([  2,   9,  11, 222,   4,   3])\n",
            "tensor([  2,   9, 136,   4,   3])\n",
            "tensor([  2,   9, 184,   4,   3])\n",
            "tensor([ 2,  9, 11, 19,  4,  3])\n",
            "tensor([  2,  25, 113,   4,   3])\n",
            "tensor([  2, 204,   7,  35,   4,   3])\n",
            "tensor([  2, 284,  15,   5,   3])\n",
            "tensor([  2, 284,  15,   4,   3])\n",
            "tensor([ 2,  0, 15,  5,  3])\n",
            "tensor([ 2,  0, 10, 15,  5,  3])\n",
            "tensor([  2, 180,   7,   0,   5,   3])\n",
            "tensor([  2, 180,  55,   0,   4,   3])\n",
            "tensor([  2, 156,  38,   4,   3])\n",
            "tensor([  2, 156,  38,   5,   3])\n",
            "tensor([ 2, 60, 16, 58,  5,  3])\n",
            "tensor([ 2,  0, 22,  4,  3])\n",
            "tensor([ 2,  0, 10, 22,  4,  3])\n",
            "tensor([ 2,  0, 10,  9,  4,  3])\n",
            "tensor([2, 0, 9, 4, 3])\n",
            "tensor([  2, 260,  15,  25,   4,   3])\n",
            "tensor([  2, 261,  10,  15,  25,   4,   3])\n",
            "tensor([ 2,  0, 22,  4,  3])\n",
            "tensor([ 2,  0, 10, 22,  4,  3])\n",
            "tensor([  2, 260,  22,  25,   4,   3])\n",
            "tensor([ 2,  0, 22, 25,  4,  3])\n",
            "tensor([  2, 261,  10,  22,  25,   4,   3])\n",
            "tensor([ 2,  0, 22,  4,  3])\n",
            "tensor([ 2, 34,  0, 25,  4,  3])\n",
            "tensor([  2,  34, 168,  95,   4,   3])\n",
            "tensor([  2,  34,  69,   7, 181,   4,   3])\n",
            "tensor([ 2, 34,  0,  7,  4,  3])\n",
            "tensor([ 2, 34,  0, 31,  4,  3])\n",
            "tensor([  2,  34, 168,  43, 154,   4,   3])\n",
            "tensor([ 2,  0, 13,  3])\n",
            "tensor([  2,  89,   0,  55, 169,   5,   3])\n",
            "tensor([ 2, 89, 51, 13,  3])\n",
            "tensor([ 2, 28,  8,  6, 13,  3])\n",
            "tensor([  2,  28,  11, 216,  13,   3])\n",
            "tensor([  2,  28, 102,  13,   3])\n",
            "tensor([  2,  28,  11, 224,  13,   3])\n",
            "tensor([ 2, 28, 64, 13,  3])\n",
            "tensor([ 2, 28, 11, 98, 13,  3])\n",
            "tensor([ 2, 28, 26, 45, 13,  3])\n",
            "tensor([  2,  28,  26, 188,  13,   3])\n",
            "tensor([ 2, 28, 11,  0, 13,  3])\n",
            "tensor([  2,  28, 266,  13,   3])\n",
            "tensor([  2,  28,  11, 222,  13,   3])\n",
            "tensor([ 2, 28, 11, 20, 13,  3])\n",
            "tensor([ 2,  0, 15,  5,  3])\n",
            "tensor([ 2,  0, 10, 15,  5,  3])\n",
            "tensor([ 2,  0, 15,  5,  3])\n",
            "tensor([ 2, 10, 69, 45,  4,  3])\n",
            "tensor([  2,  54, 139,  45,   4,   3])\n",
            "tensor([ 2,  0,  0, 45,  4,  3])\n",
            "tensor([  2, 108,  50,   4,   3])\n",
            "tensor([  2,   0,   5,   0,   0,   4, 132,   5,   3])\n",
            "tensor([ 2,  8,  6,  0, 13,  3])\n",
            "tensor([  2,   8,   6,  25, 113,  13,   3])\n",
            "tensor([  2,   8,   6,   0,   0, 127,  13,   3])\n",
            "tensor([ 2,  0,  6, 13,  3])\n",
            "tensor([ 2,  0, 53,  9,  4,  3])\n",
            "tensor([ 2,  0, 10, 15,  4,  3])\n",
            "tensor([  2, 166,  12,   5,   3])\n",
            "tensor([  2, 272,  10,  40,   4,   3])\n",
            "tensor([  2,   0, 207,   4,   3])\n",
            "tensor([2, 0, 4, 3])\n",
            "tensor([  2,  72,  46, 129,   0,  25,   5,   3])\n",
            "tensor([  2, 161, 296,  35,   5,   3])\n",
            "tensor([  2, 257,  10, 296,  35,   5,   3])\n",
            "tensor([  2, 123,  12,   5,   3])\n",
            "tensor([  2, 123,  12,   5,   3])\n",
            "tensor([  2, 192,  10,  40,   5,   3])\n",
            "tensor([  2, 192,  10,  40,   4,   3])\n",
            "tensor([ 2, 47,  6,  0, 13,  3])\n",
            "tensor([ 2,  0, 34, 31, 13,  3])\n",
            "tensor([ 2, 97,  9,  5,  3])\n",
            "tensor([2, 0, 9, 5, 3])\n",
            "tensor([  2, 201,  10,   9,   5,   3])\n",
            "tensor([  2, 202,   9,   5,   3])\n",
            "tensor([ 2, 97, 42,  4,  3])\n",
            "tensor([  2, 130,  12,   4,   3])\n",
            "tensor([  2,  33, 291,   5,   3])\n",
            "tensor([ 2, 33,  0,  4,  3])\n",
            "tensor([  2,  33, 100,   5,   3])\n",
            "tensor([  2,  71, 100,   5,   3])\n",
            "tensor([  2,  71, 140,   5,   3])\n",
            "tensor([  2,  33, 140,   5,   3])\n",
            "tensor([  2,  33, 100,   5,   3])\n",
            "tensor([  2,  33, 118,   4,   3])\n",
            "tensor([  2, 144,  10, 118,   4,   3])\n",
            "tensor([  2, 123,  12,   5,   3])\n",
            "tensor([ 2, 14,  6, 37, 13,  3])\n",
            "tensor([ 2, 17,  7, 51,  5,  3])\n",
            "tensor([ 2, 17,  7, 51,  0,  4,  3])\n",
            "tensor([2, 0, 0, 4, 3])\n",
            "tensor([ 2, 66, 21,  4,  3])\n",
            "tensor([ 2,  0, 21,  5,  3])\n",
            "tensor([  2, 289,  21,   4,   3])\n",
            "tensor([  2, 288,  10,  21,   4,   3])\n",
            "tensor([  2, 288,  10,  21,   5,   3])\n",
            "tensor([  2, 289,  21,   5,   3])\n",
            "tensor([ 2,  0, 21,  5,  3])\n",
            "tensor([  2, 150,  21,   5,   3])\n",
            "tensor([  2, 150,  21,   4,   3])\n",
            "tensor([  2, 146,  21,   4,   3])\n",
            "tensor([  2,   7, 173,  15, 243,   4,   3])\n",
            "tensor([ 2, 63,  5,  3])\n",
            "tensor([ 2, 63,  4,  3])\n",
            "tensor([ 2,  0, 10,  5,  3])\n",
            "tensor([  2, 285,   4,   3])\n",
            "tensor([  2, 285,  13,   3])\n",
            "tensor([  2, 203,   5,   3])\n",
            "tensor([2, 0, 0, 5, 3])\n",
            "tensor([ 2,  0, 38,  4,  3])\n",
            "tensor([  2, 208,  15,   4,   3])\n",
            "tensor([  2, 208,  22,   5,   3])\n",
            "tensor([ 2,  0, 10, 22,  5,  3])\n",
            "tensor([  2, 174,   7,   5,   3])\n",
            "tensor([2, 0, 0, 0, 4, 3])\n",
            "tensor([  2, 174,   7,   4,   3])\n",
            "tensor([ 2, 16,  0, 54,  0,  4,  3])\n",
            "tensor([  2, 174,  18,   5,   3])\n",
            "tensor([ 2,  0, 18,  5,  3])\n",
            "tensor([ 2,  0, 10, 18,  5,  3])\n",
            "tensor([ 2, 17, 12,  0,  5,  3])\n",
            "tensor([  2,  17,  12, 205,   4,   3])\n",
            "tensor([  2, 252,  25,   5,   3])\n",
            "tensor([  2, 279,   7,   4,   3])\n",
            "tensor([ 2,  0, 46,  5,  3])\n",
            "tensor([  2,  27, 158,   5,   3])\n",
            "tensor([  2,  33, 158,   4,   3])\n",
            "tensor([ 2, 27, 77,  4,  3])\n",
            "tensor([ 2, 27, 77,  5,  3])\n",
            "tensor([ 2, 67, 77,  5,  3])\n",
            "tensor([ 2, 31, 10, 77,  5,  3])\n",
            "tensor([  2,  27, 239, 193,   5,   3])\n",
            "tensor([  2,  32, 239, 193,   5,   3])\n",
            "tensor([  2, 148,  50,  77,   5,   3])\n",
            "tensor([2, 0, 0, 4, 3])\n",
            "tensor([2, 0, 0, 4, 3])\n",
            "tensor([ 2, 60, 16,  4,  3])\n",
            "tensor([  2, 143,  16,   4,   3])\n",
            "tensor([ 2,  0, 46, 16,  4,  3])\n",
            "tensor([  2, 237,  30,   5,   3])\n",
            "tensor([  2,  60,  46, 125,   4,   3])\n",
            "tensor([  2, 250,  10, 125,   4,   3])\n",
            "tensor([  2,  20,  11, 104,   4,   3])\n",
            "tensor([  2,  20,  11, 117,   4,   3])\n",
            "tensor([  2,  20, 254,  40,   4,   3])\n",
            "tensor([  2,  20, 246,   4,   3])\n",
            "tensor([  2,  20,  11, 197,   4,   3])\n",
            "tensor([ 2, 20, 11,  0,  4,  3])\n",
            "tensor([  2,  20,  11, 264,   4,   3])\n",
            "tensor([ 2, 20, 11, 29,  4,  3])\n",
            "tensor([ 2, 20, 11,  0,  4,  3])\n",
            "tensor([  2,  20,  11, 255,   4,   3])\n",
            "tensor([ 2, 20, 11,  0,  4,  3])\n",
            "tensor([  2, 199, 159, 155,   4,   3])\n",
            "tensor([  2, 200,  10, 159, 155,   4,   3])\n",
            "tensor([  2,   0, 159, 155,   4,   3])\n",
            "tensor([ 2, 58,  8,  6,  4,  3])\n",
            "tensor([  2,  58, 168,   0,   0,   4,   3])\n",
            "tensor([ 2, 21,  0,  5,  3])\n",
            "tensor([  2, 138,  16,   5,   3])\n",
            "tensor([  2, 138,  16,  38,   4,   3])\n",
            "tensor([  2, 228,  10,  16,   5,   3])\n",
            "tensor([  2, 229,  16,   5,   3])\n",
            "tensor([2, 0, 5, 3])\n",
            "tensor([ 2, 48, 11, 41,  0, 13,  3])\n",
            "tensor([ 2, 48,  0,  5,  3])\n",
            "tensor([  2, 106,   9,  94, 271, 293,   4,   3])\n",
            "tensor([  2, 107,   9,  94, 271, 293,   4,   3])\n",
            "tensor([ 2, 15, 68, 29,  4,  3])\n",
            "tensor([ 2, 15, 32,  7, 29,  4,  3])\n",
            "tensor([ 2,  7, 32, 15, 29,  4,  3])\n",
            "tensor([ 2,  6,  8, 58,  4,  3])\n",
            "tensor([ 2,  7, 32, 15, 29,  4,  3])\n",
            "tensor([  2,   6,   8, 167,   4,   3])\n",
            "tensor([  2,   6,   8, 137,   4,   3])\n",
            "tensor([  2,   6,   8, 265,   4,   3])\n",
            "tensor([ 2, 15, 32,  7, 29,  4,  3])\n",
            "tensor([ 2,  7, 32, 15, 29,  4,  3])\n",
            "tensor([ 2,  6,  8, 95,  4,  3])\n",
            "tensor([  2,   6,  47, 207,   4,   3])\n",
            "tensor([  2,   6,  47, 242,   4,   3])\n",
            "tensor([ 2,  6, 47,  0,  4,  3])\n",
            "tensor([  2,   6,  47,   0, 200,   4,   3])\n",
            "tensor([ 2,  6, 47,  0,  4,  3])\n",
            "tensor([ 2,  6,  0, 18,  4,  3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([ 2,  6, 90,  0,  4,  3])\n",
            "tensor([ 2,  6, 64, 43,  0,  4,  3])\n",
            "tensor([ 2,  6,  0, 53,  0,  4,  3])\n",
            "tensor([ 2,  6,  0, 41,  0,  4,  3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([ 2,  6,  0, 19,  4,  3])\n",
            "tensor([  2,   6, 179,  53,  89,  54,   0,   4,   3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([  2,   6, 133,  19,   4,   3])\n",
            "tensor([  2,   6, 133, 108,   4,   3])\n",
            "tensor([ 2,  6,  0, 18,  4,  3])\n",
            "tensor([  2,   6, 133,  19,   4,   3])\n",
            "tensor([ 2,  6,  0, 49, 19,  4,  3])\n",
            "tensor([ 2, 15, 90, 57,  4,  3])\n",
            "tensor([ 2,  6, 90,  0,  4,  3])\n",
            "tensor([ 2,  6, 90,  0,  4,  3])\n",
            "tensor([ 2,  6, 14, 12,  4,  3])\n",
            "tensor([  2,   6, 231, 169,   4,   3])\n",
            "tensor([ 2,  6, 14, 18,  0,  4,  3])\n",
            "tensor([ 2,  6, 14,  7,  4,  3])\n",
            "tensor([ 2,  6, 14,  9,  0,  4,  3])\n",
            "tensor([  2,   6, 262,   9,   4,   3])\n",
            "tensor([2, 6, 0, 9, 4, 3])\n",
            "tensor([  2,  16, 236,   6,   4,   3])\n",
            "tensor([  2,   6, 236,   7,   4,   3])\n",
            "tensor([ 2,  6, 14,  0,  4,  3])\n",
            "tensor([ 2,  6, 14, 18,  0,  4,  3])\n",
            "tensor([  2,   6, 115,   7,   4,   3])\n",
            "tensor([  2,   6, 115,  16,   4,   3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2, 16,  0, 15,  4,  3])\n",
            "tensor([  2,   7,  11,  15, 157,   4,   3])\n",
            "tensor([ 2,  6, 14, 42, 45,  4,  3])\n",
            "tensor([  2,   6, 244,   7,   5,   3])\n",
            "tensor([  2,   6, 244,   7,   4,   3])\n",
            "tensor([  2,   6,  14,   7, 218,   4,   3])\n",
            "tensor([  2,   6,  14,   7, 221,   4,   3])\n",
            "tensor([2, 0, 0, 6, 4, 3])\n",
            "tensor([  2,   6, 151,   7, 273,   5,   3])\n",
            "tensor([  2,   6, 151,   7,  96,   5,   3])\n",
            "tensor([  2,   6, 151,   7,  96,   4,   3])\n",
            "tensor([ 2,  7, 11, 96,  0,  0, 15,  4,  3])\n",
            "tensor([  2,   6,  14,   9, 135,   4,   3])\n",
            "tensor([2, 6, 0, 9, 4, 3])\n",
            "tensor([2, 6, 8, 9, 0, 4, 3])\n",
            "tensor([  2,   6,  14,  42, 135,   4,   3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([ 2,  7,  0, 15,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([ 2,  6,  0, 18,  4,  3])\n",
            "tensor([ 2,  6, 14, 18,  0,  4,  3])\n",
            "tensor([  2,   6, 136,  43,   0,   4,   3])\n",
            "tensor([  2,   6,   0, 251,   4,   3])\n",
            "tensor([ 2,  6, 14,  9, 56,  4,  3])\n",
            "tensor([ 2,  6, 14, 42, 56,  4,  3])\n",
            "tensor([ 2,  6, 14,  0, 56,  4,  3])\n",
            "tensor([ 2,  6, 14, 12, 56,  4,  3])\n",
            "tensor([ 2,  6, 14, 50, 56,  4,  3])\n",
            "tensor([ 2,  6, 14, 10, 56,  4,  3])\n",
            "tensor([  2,   6, 269,   9,   4,   3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([  2,   6,   0, 190,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6,  0, 19,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([ 2,  6, 14,  7,  0,  4,  3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([2, 6, 0, 7, 4, 3])\n",
            "tensor([  2,   6,  87, 104,   4,   3])\n",
            "tensor([  2,   6,  87, 176,   4,   3])\n",
            "tensor([  2,   6,  87, 109,   4,   3])\n",
            "tensor([  2,   6,  87, 171,   4,   3])\n",
            "tensor([  2,   6,  87, 268,   4,   3])\n",
            "tensor([ 2,  6, 67,  4,  3])\n",
            "tensor([ 2,  6, 24, 31,  4,  3])\n",
            "tensor([ 2,  6,  0, 19,  4,  3])\n",
            "tensor([  2,   6, 295,   7, 172,   4,   3])\n",
            "tensor([  2,   6, 295,  31,   4,   3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([  2,   6,  24, 144,   4,   3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([2, 6, 0, 4, 3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([  2,   6,  24, 189,   4,   3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([  2,   6,  24, 124,   4,   3])\n",
            "tensor([  2,   6,  24, 189,   4,   3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([ 2,  6, 24,  0,  4,  3])\n",
            "tensor([  2,   6,  24, 182,   4,   3])\n",
            "tensor([  2,   6,  67,  25, 213,   4,   3])\n",
            "tensor([  2,   6,  24,  25, 213,  31,   4,   3])\n",
            "tensor([  2,   6,   8,  55, 248,   4,   3])\n",
            "tensor([ 2,  6,  8, 55,  0,  4,  3])\n",
            "tensor([  2,   6,   8, 129, 275,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,   8, 275,   4,   3])\n",
            "tensor([  2,   6,   8, 116,   4,   3])\n",
            "tensor([  2,   6,   8, 259,   4,   3])\n",
            "tensor([  2,   6,   8, 114,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([ 2, 15, 11,  0,  4,  3])\n",
            "tensor([2, 6, 8, 0, 0, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,   8, 176,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,  24, 118,   0,   4,   3])\n",
            "tensor([  2,   6,   8,   0, 127,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,   8, 253,   4,   3])\n",
            "tensor([ 2,  6, 67, 51,  4,  3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6, 150,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,   8, 206,   4,   3])\n",
            "tensor([  2,   6,   8, 253,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   6,   8, 274,   5,   3])\n",
            "tensor([  2,   6,   8, 274,   4,   3])\n",
            "tensor([  2,   6,   8, 273, 290,   4,   3])\n",
            "tensor([  2,   6,  14, 157,   4,   3])\n",
            "tensor([  2,   6,  14, 157,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([  2,   7, 173,  15, 243,   4,   3])\n",
            "tensor([ 2, 63,  5,  3])\n",
            "tensor([ 2, 63,  4,  3])\n",
            "tensor([2, 6, 0, 0, 4, 3])\n",
            "tensor([  2,   6,   8, 249,   5,   3])\n",
            "tensor([  2,   6,   8, 249,   4,   3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([2, 6, 8, 0, 4, 3])\n",
            "tensor([ 2,  6, 14, 18,  0,  4,  3])\n",
            "tensor([2, 6, 0, 0, 4, 3])\n",
            "tensor([ 2,  6,  0, 46,  4,  3])\n",
            "tensor([ 2,  6, 14, 45,  4,  3])\n",
            "tensor([  2,   0,   7, 214,  21,   5,   3])\n",
            "tensor([  2,   0,  10,   7, 214,  21,   5,   3])\n",
            "tensor([ 2, 11,  9,  0, 13,  3])\n",
            "tensor([ 2, 11,  9, 93, 13,  3])\n",
            "tensor([ 2, 11, 16,  9, 13,  3])\n",
            "tensor([ 2, 11, 20,  9, 13,  3])\n",
            "tensor([ 2, 11, 16,  9, 13,  3])\n",
            "tensor([ 2, 11,  7,  0, 13,  3])\n",
            "tensor([  2,  11,   7, 163,  13,   3])\n",
            "tensor([  2,  11,  16, 290,  13,   3])\n",
            "tensor([ 2, 11,  7, 57, 13,  3])\n",
            "tensor([  2,  11,   7, 109,  13,   3])\n",
            "tensor([  2,  11,   7, 160,  13,   3])\n",
            "tensor([  2,  11,  10, 160,  13,   3])\n",
            "tensor([ 2, 10, 26, 18,  0,  4,  3])\n",
            "tensor([2, 7, 0, 4, 3])\n",
            "tensor([2, 7, 0, 4, 3])\n",
            "tensor([2, 7, 0, 4, 3])\n",
            "tensor([ 2,  7, 26,  0,  4,  3])\n",
            "tensor([ 2, 93, 11, 94, 89,  0,  4,  3])\n",
            "tensor([ 2,  7, 26,  0,  4,  3])\n",
            "tensor([  2,  16,  26, 212,   4,   3])\n",
            "tensor([ 2,  7, 11,  0,  0,  4,  3])\n",
            "tensor([ 2,  7, 11,  0, 81,  4,  3])\n",
            "tensor([ 2,  7, 11,  0, 81,  0,  4,  3])\n",
            "tensor([ 2,  7, 11,  0, 81,  4,  3])\n",
            "tensor([ 2,  7, 11, 51,  0, 81,  4,  3])\n",
            "tensor([  2,   7,  11,   0, 108,   0,   4,   3])\n",
            "tensor([ 2,  7, 11,  0,  0, 81,  4,  3])\n",
            "tensor([ 2, 16, 11, 55,  0,  4,  3])\n",
            "tensor([ 2,  7, 11,  0,  4,  3])\n",
            "tensor([ 2,  7, 11,  0,  4,  3])\n",
            "tensor([ 2,  7, 11,  0,  4,  3])\n",
            "tensor([  2,  16,  11, 198,   4,   3])\n",
            "tensor([  2,   7,  11, 198,   4,   3])\n",
            "tensor([  2,   7,  11, 220,   4,   3])\n",
            "tensor([  2,   7,  11, 211,   4,   3])\n",
            "tensor([ 2,  7, 11,  0,  4,  3])\n",
            "tensor([ 2,  7, 11,  0,  4,  3])\n",
            "tensor([ 2,  7, 11, 30,  4,  3])\n",
            "tensor([ 2, 16, 11,  0,  4,  3])\n",
            "tensor([ 2,  7, 11, 58,  4,  3])\n",
            "tensor([  2,   7,  11, 113,   4,   3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Totes les primeres files de cada batch estan plenes de 2, com l'inici de tots els en_ids o de_ids, que representa el eos"
      ],
      "metadata": {
        "id": "YifcTTheAqIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = train_data_loader\n",
        "a,b = 0,0\n",
        "\n",
        "for batch in loader:\n",
        "  print(batch['en_ids'])\n",
        "\n",
        "num_batches = len(loader)\n",
        "print(f'Número de batches: {num_batches}')  #número de batches dins del loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C97gWhFq0vSh",
        "outputId": "15cf74d7-4d71-4a27-9a1d-0374338fa05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2],\n",
            "        [ 55,   5,   6,  49,  10,  97,   5,  11, 140,   5,   5,   5,  11,  18,\n",
            "           5,   0, 161,   5,  94,  38,  10,  30,  11,  79, 113,   5,   5,  87,\n",
            "           6,   5,   5,   5,  10,   5,   5,   6,   0, 124,   5, 162, 157, 197,\n",
            "          26,   5,  96,   9,  10,  10, 186,  55,  52,  11,  35,   9,  22,   5,\n",
            "          11,  80,  24,  39,  10,  44, 198,  44,   5,   5,   5,   5, 155,  20,\n",
            "           6,   6,   6,   5,   5,   5, 259,   5,  25,   5,   5,   5,   5,  55,\n",
            "          52,   5,   5,  27,  24,  20,  94,  26,   6,  80,   0,   5,  41, 139,\n",
            "           5,   5,  22, 100,  15,  73,  44,   5,  25, 130,  39,   5,   5,  31,\n",
            "           5,  37,   5,   5,   5,   5,  11,  11,   5,   6,   9,  62,  62,  11,\n",
            "          18,   0],\n",
            "        [ 15,   0,  13,   5,  12,   7,   0,  12,   7,   8, 184, 226,  12, 151,\n",
            "           0,   4, 137,   8,  29,  21,   0,   6,  12, 243,  16,   0, 192,  27,\n",
            "          13,   8,   8,  22,  12,   8,  30,   0, 146,   6,  19,  15,   7,   4,\n",
            "          36,  84,  33,  88,  12,  12,   7,   6,  21,  17, 108,   0,   5, 177,\n",
            "          17,  16,  40,  51,  12,   9,  40,   9,   8,   8,  84,   8,  29,  34,\n",
            "          13,  13,  13,   8,  46, 219,   7,  89,  92,  22,  19, 138, 195,  15,\n",
            "          21,  30, 104, 119,  50,  95,  29,  36,  13,  16,   4,   8,   9, 132,\n",
            "           8,  17,   5,   9,  91,   7,   9,  19,  43,   6,  51, 160,  89,   6,\n",
            "           8,  88,  22,   8, 211,   8,  17,  45,   8,  13, 226,   7,   9,  86,\n",
            "          13,   7],\n",
            "        [  4,   4, 167,  22,   7,   3,   4,   7,   3,  86,   4,   4,   7,   4,\n",
            "          16,   3,  14,  78,   7,   4,   4,   7,   7,   4,   7,   4,   4,   4,\n",
            "          15,  34,  86, 217,   7,   0,  83,   4,   4,   4, 250,   4,   3,   3,\n",
            "          39,   6,   4,   4,   7,   4,   3,   4,   4,   7,   7,   4,  71,   4,\n",
            "           7,   4,   7,   4,   4,   4,   4,   4, 187, 218,   6, 108,   4, 212,\n",
            "         193, 165,   0, 121,   4,   4,   3, 105,  14,  78,  47,  67,  16,   4,\n",
            "           4,   6,  69,   4,   4,   4,   4,  75,   0,   4,   3, 102,   4,   4,\n",
            "          34,   4, 102,   4, 158,   3,   4,   0,  14,   7,   4,   4,  83,   7,\n",
            "         170,   4,  78,  71,   6, 111,   7,   7, 216, 196,   4,   3,   4,   4,\n",
            "           9,   3],\n",
            "        [  3,   3,   4,   4,   3,   1,   3,   3,   1,   4,   3,   3,   3,   3,\n",
            "           4,   1,   3,   4,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
            "           7,   0,   4,   4,   3,   4,   4,   3,   3,   3,   4,   3,   1,   1,\n",
            "           4,   7,   3,   3,   3,   3,   1,   3,   3,   3,   3,   3,  14,   3,\n",
            "           3,   3,   3,   3,   3,   3,   3,   3,   4,   4,   4,   4,   3,   4,\n",
            "           4,   4,   4,   4,   3,   3,   1,   4,   3,   4,   4,   4,   4,   3,\n",
            "           3,   4,   4,   3,   3,   3,   3,   4,   4,   3,   1,   4,   3,   3,\n",
            "         129,   3,  14,   3,   4,   1,   3,   4,   3,   3,   3,   3,   4,   3,\n",
            "           4,   3,   4,   4,   4,   4,   3,   3,   4,   4,   3,   1,   3,   3,\n",
            "           4,   1],\n",
            "        [  1,   1,   3,   3,   1,   1,   1,   1,   1,   3,   1,   1,   1,   1,\n",
            "           3,   1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           3,   4,   3,   3,   1,   3,   3,   1,   1,   1,   3,   1,   1,   1,\n",
            "           3,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   3,   3,   3,   3,   1,   3,\n",
            "           3,   3,   3,   3,   1,   1,   1,   3,   1,   3,   3,   3,   3,   1,\n",
            "           1,   3,   3,   1,   1,   1,   1,   3,   3,   1,   1,   3,   1,   1,\n",
            "           4,   1,   3,   1,   3,   1,   1,   3,   1,   1,   1,   1,   3,   1,\n",
            "           3,   1,   3,   3,   3,   3,   1,   1,   3,   3,   1,   1,   1,   1,\n",
            "           3,   1],\n",
            "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1]])\n",
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2],\n",
            "        [185,  41,  56,   0,  31,   5,  18,   9,   5,   6,  20,   5,   5,  68,\n",
            "          99,  63,   5,  10, 249, 161,   6,  26,  11,   5,   5,   0,   5,  46,\n",
            "          18,  22,  41,   5,   5,   5, 152,   5,  99,  18,  38,  35,   5,   5,\n",
            "           5,   5,  10,  31, 157,   6,   9,  11, 134,   5,   5,  10,   5,   5,\n",
            "         107,  48,  23,   5,  23, 202,   5,   5,  24, 149, 175,   5,  25,  63,\n",
            "          44,   5,  11,  10,  37,  10,  26,  18, 113,   5,  18,   5,  20,   5,\n",
            "           9,   5,   5,  25,   5,  25,   0,   5,   6,  18,  10, 140,  24,   5,\n",
            "          10, 117,  24,  63, 235,  63,   5,   5, 130,   6,  10,   5,   5, 134,\n",
            "           5,   5,   5, 139,   5,  59,  11,   5, 117,  32,  18,   6,  10,   6,\n",
            "           0,   5],\n",
            "        [  7,  15,   9,   6,   6, 183,   0,  60,  72, 258,  93,  22, 240, 110,\n",
            "          15,   9,   8,  12,  21, 106,  13,  36,  12,   8, 210,   7,   8,   6,\n",
            "          60,   5,  15, 160, 256,  22,   9, 221,   9, 151,   9, 126,   8,  77,\n",
            "          72, 222,  12,   6,   7,  13,  81,  17,   9,   8,   8, 106,  43, 163,\n",
            "           6,   9,   6,  42,   6,   4,   8, 188, 234,  14,  34, 253,  92,   9,\n",
            "           9,   0,  12,  12, 115,  12,  36, 115,  16,   0,  28,   8,   0,  19,\n",
            "         128, 256,   8,  85,   0,  13,  15, 245,  13, 153,  57,   7,  40, 127,\n",
            "           4,  16,  50,   9,   4,  15,   8,   8,   6,  13,  12,  19,   8,   9,\n",
            "           8, 239,   0, 132, 184,  90,  29,   8,  16,   6,  13,  13, 207,  13,\n",
            "          15,   8],\n",
            "        [  3,   4,   4,   4,   4,   4,   4,   4,  27,   4,   4, 241,   4,   4,\n",
            "           4,   4,   0,   7,   4,  14,   0,   0,   7,   0,   6,   3, 174,   4,\n",
            "           4,   0,   4,   4,   4, 254,   4,   4,   4,   4,   4,   7, 224,  16,\n",
            "           9,   4,   7,   4,   3,   0,   4,   7,   4, 194,  84,   4,   4,  82,\n",
            "           4,   4,   4,  61,   4,   3,  34,   4,   4,   3,   0,   4,  14,   4,\n",
            "           4,   4,   7,   7,   4,   4,  39,   4,   7,   4, 218, 199,   4,   0,\n",
            "           4,   4, 133,  14,  16,  18,   4,   6,   0,   4,   4,   3,   7,   6,\n",
            "           3,   4,   4,   4,   3,   4, 244, 135,   4, 102,   4,  10,  16,   4,\n",
            "           0,   4,   4,   4,   4,   7,   7, 220,   7,   4,   0,  15,   4,  49,\n",
            "          14, 171],\n",
            "        [  1,   3,   3,   3,   3,   3,   3,   3,   4,   3,   3,   4,   3,   3,\n",
            "           3,   3,   4,   3,   3,   3,   4,   4,   3,   4,   7,   1,   4,   3,\n",
            "           3,  14,   3,   3,   3,   4,   3,   3,   3,   3,   3,   3,   4,   4,\n",
            "           4,   3,   3,   3,   1,   4,   3,   3,   3,   4,   4,   3,   3,   4,\n",
            "           3,   3,   3,   4,   3,   1, 156,   3,   3,   1,   4,   3,   3,   3,\n",
            "           3,   3,   3,   3,   3,   3,   4,   3,   3,   3,   4,   4,   3,   4,\n",
            "           3,   3,   4,   3,   4,  14,   3,   4,   4,   3,   3,   1,   3,   4,\n",
            "           1,   3,   3,   3,   1,   3,   4,   4,   3,   4,   3,   4,   4,   3,\n",
            "           4,   3,   3,   3,   3,   3,   3,   4,   3,   3,   4,   4,   3,   4,\n",
            "           3,   4],\n",
            "        [  1,   1,   1,   1,   1,   1,   1,   1,   3,   1,   1,   3,   1,   1,\n",
            "           1,   1,   3,   1,   1,   1,   3,   3,   1,   3,   3,   1,   3,   1,\n",
            "           1,   3,   1,   1,   1,   3,   1,   1,   1,   1,   1,   1,   3,   3,\n",
            "           3,   1,   1,   1,   1,   3,   1,   1,   1,   3,   3,   1,   1,   3,\n",
            "           1,   1,   1,   3,   1,   1,   4,   1,   1,   1,   3,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   3,   1,   1,   1,   3,   3,   1,   3,\n",
            "           1,   1,   3,   1,   3,   3,   1,   3,   3,   1,   1,   1,   1,   3,\n",
            "           1,   1,   1,   1,   1,   1,   3,   3,   1,   3,   1,   3,   3,   1,\n",
            "           3,   1,   1,   1,   1,   1,   1,   3,   1,   1,   3,   3,   1,   3,\n",
            "           1,   3],\n",
            "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   3,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1]])\n",
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2],\n",
            "        [  5,   5,   5,   5,   5,   5,   5,   5,  48,   5,  47,   0,   5,  62,\n",
            "          10,  25,   5,  23,   5,  11,  11,  38, 152, 159,  18,  28,  24,  55,\n",
            "           5,  38,   6,  23, 124, 169,  20,  47,  97,  52,   5,  11,   9,  11,\n",
            "          10,   5,  44,  68,  18,   5,  20,   5,   0,  10,   5,  27,  26,   5,\n",
            "          76,   5,   5,  52,  66,  20,   5,  11,  25,  28,  58,  23,   5,  79,\n",
            "           0,   5,   5,   5,   6,  11,   6,   0,   5,   5,   5,   9,   5,  10,\n",
            "          26,  10,  18,   5,  23,   5,  35,  79,   5, 252,   6, 229, 134,  32,\n",
            "           0,   5,  11,   5,   5,   5,   9,   5,  47,  76,  25,   6,  10,  82,\n",
            "           5,  39,  10,  11,  46,  66, 175,  18, 203,  27,   5,  87,  10,   5,\n",
            "         154,  42],\n",
            "        [  8,   0, 248,   8, 138,  56,   0, 104,  15,   8,  57,  15,   8,   7,\n",
            "          12,  43,  81,   6,   8,  29,  17,   9,   9,  16,  13,   6,  40,   6,\n",
            "          98,  21,   0,   6,   6,   7,  74,  57,   4,  15,   8,  17,  98,  45,\n",
            "          12, 176,  15, 110,  13,  30, 123,  42,  91,  12,   8,  17,   6,  81,\n",
            "           6,  42,   0,  15,  15,   0,   8,  17,  60,   6,  13,   6,  19, 243,\n",
            "           6,  19,   8, 215,   0,  12,  13,   6,   8,  42, 236, 143,   8,  12,\n",
            "          36, 137, 103,  43,   6, 153, 225,   9, 179,   9,  13,  15,   9,   6,\n",
            "          33, 143,  29, 240,   8,   8,  53, 232,   9,  16,  65, 173,  12,  21,\n",
            "         255,  51,  12,  12,  33,  15,   6,  60,  50,  53,   8,  27,  64,   8,\n",
            "         103,   5],\n",
            "        [172,  59,   6, 260,  67,   9,   4,   9,   4, 220,   7,   4, 194,   3,\n",
            "           4,  14,   6,   4,  16,   7,   7,   4,   4,   4,   0, 122,   7,   4,\n",
            "           4,   4,   4,   4,   4,   3,   4,   7,   3,   4,   0,   7,   4,   4,\n",
            "           4,   4,   4,   4,   0,  27,   4, 189,   9,   7, 193,   4,   4,   6,\n",
            "           4,  61,   4,   4,   4,   4,  83,   7,  14,   9,  10,   4,  85,   4,\n",
            "           4,   0, 131,   4,   4,   7,   0,   4,   0, 119,   4,   4, 180,   7,\n",
            "          10,   6,   4,   4,   4,   4,   7,   4,   4,   4, 105,   4,   4,   4,\n",
            "           4,   4,   4,   4, 133,   0,   4,   4,   4,   4,  14,   4,   7,   4,\n",
            "          10,   4,   4,   7,   4,   4,   4,   4,   4,   4,   0,   7,  54,   0,\n",
            "           4,  76],\n",
            "        [  4,   4,   4,   4,   4,   4,   3,   4,   3,   4,   3,   3,   4,   1,\n",
            "           3,   3,   4,   3,   4,   3,   3,   3,   3,   3,   4,  14,   3,   3,\n",
            "           3,   3,   3,   3,   3,   1,   3,   3,   1,   3,   4,   3,   3,   3,\n",
            "           3,   3,   3,   3,   4,   4,   3,   4,   4,   3,   4,   3,   3,   4,\n",
            "           3,   4,   3,   3,   3,   3,   4,   3,   3,  14,   7,   3,   4,   3,\n",
            "           3,   4,   4,   3,   3,   3,   4,   3,   4,   4,   3,   3,   4,   3,\n",
            "           4,   4,   3,   3,   3,   3,   3,   3,   3,   3,   4,   3,   3,   3,\n",
            "           3,   3,   3,   3,   4,   4,   3,   3,   3,   3,   3,   3,   3,   3,\n",
            "           4,   3,   3,   3,   3,   3,   3,   3,   3,   3,   4,   3,   4,   4,\n",
            "           3,  14],\n",
            "        [  3,   3,   3,   3,   3,   3,   1,   3,   1,   3,   1,   1,   3,   1,\n",
            "           1,   1,   3,   1,   3,   1,   1,   1,   1,   1,   3,   3,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,   1,   1,\n",
            "           1,   1,   1,   1,   3,   3,   1,   3,   3,   1,   3,   1,   1,   3,\n",
            "           1,   3,   1,   1,   1,   1,   3,   1,   1,   3,   3,   1,   3,   1,\n",
            "           1,   3,   3,   1,   1,   1,   3,   1,   3,   3,   1,   1,   3,   1,\n",
            "           3,   3,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,   1,   1,\n",
            "           1,   1,   1,   1,   3,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,   3,   3,\n",
            "           1,   3]])\n",
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2],\n",
            "        [191,   5,  94,  66,   5,   5,   9,  25,   5,   5, 208,   5,  18,   5,\n",
            "           5,  10,   5,   6,  20,  31,   5,   0,   9,  41,   6,   9,  28,   5,\n",
            "          56,   6,   5,  24, 144,   6,   5,  10,  59,  47,  97,  38, 136, 206,\n",
            "          20,   5,   5,  39,   5, 242,   5,  52,  10,   9,   5,   5, 228,  11,\n",
            "          31,   5, 162,   5,  46,   5,  25, 121,  62,  73,   5,   5,   5,  52,\n",
            "           5,   5,   6,  68, 101,  35,   6,   5, 229,   0,   5,   5,   9,   5,\n",
            "          68, 191,   9,   5,   5,  37,   5,  28,   5,   5,   5,  99,   5,  66,\n",
            "           5,  35,   0,  11,  20,   9,  32,   5,  18,  23,   5,   0,   5,  80,\n",
            "          63,   5,  58,  97,   6,   5,  59,  10,  25,   5,  15,  48,   5,  11,\n",
            "          20,  41],\n",
            "        [  7, 209,  29,  15,  72,   8, 128,  17, 214,   8,  21,  19, 233,   8,\n",
            "          22,  12,  72,  13, 227,  33,   8,   0,  43,   9,  13, 147,   6,   8,\n",
            "           9, 258,   8,  49,   6,  13, 251,  57,  90,   9,   7,   9,  21,   6,\n",
            "          93,  19, 112,  51,  11,   7,   8,  21, 168,  81,  19, 120,   7,  17,\n",
            "           6, 215,  15,   0, 110,   8,  53, 146,   9,  16,   8, 163, 181,  21,\n",
            "           8,  11,   0,  67,  15,  28, 205, 104,  15,   4, 237,   8, 112,  19,\n",
            "          67,   7, 160, 183,   8, 120,   8,   6,   8,   8,   8,  15,   0,  15,\n",
            "         221,   0,  27,  17, 123,  92,  45,   8,  13,   6, 176,  59, 204,   7,\n",
            "          15,   0,  13,   7,  13,  53,  90,  12,  60, 236,  91,   9, 261,  29,\n",
            "         148,  15],\n",
            "        [  3,   6,   4,   4,  27,  57,   4,  14,   6,  95,   4, 235,   4, 247,\n",
            "          49,   4,   0,  70,   4,   4, 199,   4,   4,   4, 108,   4, 150,   0,\n",
            "           4,   4, 131,   4,   4,  34,   6,   4,   7,   4,   3,   4,   4,   4,\n",
            "           4,   0,   4,   4, 125,   3,  17,   4,   4,   4,   0,   4,   3,   7,\n",
            "           4,   4,   4,   4,   4, 224,  14,   4,   4,   4,   0,  26,   4,   4,\n",
            "         172,  27,   4,   4,   4,   6,   4,   9,   4,   3,   4, 244,   4,  85,\n",
            "           4,   3,   4,   4,   0,   4, 135, 150, 260, 118, 230,   4,   4,   4,\n",
            "           4,   7,   4,   4,   4,   4,   4, 246, 223,   4,   4,   7, 109,   3,\n",
            "           4,   4,  10,   3, 182,   7,   7,   4,  14,   4, 158,   4,   4,   7,\n",
            "           4,   4],\n",
            "        [  1,   4,   3,   3,   4,   4,   3,   3,   4,   4,   3,   4,   3,   4,\n",
            "           4,   3,   4,   4,   3,   3,   4,   3,   3,   3,   4,   3,  14,   4,\n",
            "           3,   3,   4,   3,   3,   0,   4,   3,   3,   3,   1,   3,   3,   3,\n",
            "           3,   4,   3,   3,   4,   1,   4,   3,   3,   3,   4,   3,   1,   3,\n",
            "           3,   3,   3,   3,   3,   4,   3,   3,   3,   3,   4,   6,   3,   3,\n",
            "           4,   4,   3,   3,   3,  14,   3,   4,   3,   1,   3,   4,   3,   4,\n",
            "           3,   1,   3,   3,   4,   3,   4,  14,   4,   4,   4,   3,   3,   3,\n",
            "           3,   3,   3,   3,   3,   3,   3,   4,   4,   3,   3,   3,   4,   1,\n",
            "           3,   3,   7,   1,   4,   3,   3,   3,   3,   3,   4,   3,   3,   3,\n",
            "           3,   3],\n",
            "        [  1,   3,   1,   1,   3,   3,   1,   1,   3,   3,   1,   3,   1,   3,\n",
            "           3,   1,   3,   3,   1,   1,   3,   1,   1,   1,   3,   1,   3,   3,\n",
            "           1,   1,   3,   1,   1,   4,   3,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   3,   1,   1,   3,   1,   3,   1,   1,   1,   3,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   3,   1,   1,   1,   1,   3,   4,   1,   1,\n",
            "           3,   3,   1,   1,   1,   3,   1,   3,   1,   1,   1,   3,   1,   3,\n",
            "           1,   1,   1,   1,   3,   1,   3,   3,   3,   3,   3,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   3,   3,   1,   1,   1,   3,   1,\n",
            "           1,   1,   3,   1,   3,   1,   1,   1,   1,   1,   3,   1,   1,   1,\n",
            "           1,   1],\n",
            "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1]])\n",
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2],\n",
            "        [ 58,   0,   6,  28,  73,  10,   5,   5,  61,   5,  30,  10,   5,  55,\n",
            "          11,  10,   6,  39,  11, 197, 139,   5,   5,   5,  28,  47,   5,  32,\n",
            "          58, 107,  11,  11,  11,   0,   5,   6,  10,  66,  11, 249,   5,  10,\n",
            "          35,   5,  32,  46,   6,   5,   5,  82,  52,   5,   9,  24,  48,  24,\n",
            "          44,  61,   0,  20,  63,   5, 208,   5,  25,   5,  26,   0,   5,  10,\n",
            "         100,  10,  42,   5,  18, 198,   5,   5,   5,  11,  96,   0,   9,  27,\n",
            "           5,   5,  10, 107,  63,  49,   5, 144,  18,  79,  24,   5, 114,   9,\n",
            "          28,  58,   5,   5,  73,   5,   5,   5,   5,  10,   6,  55,   5,  26,\n",
            "           5,   5,  76,  25,   9,  10,  25,   6,  56, 248,   5,   6,  38,   6,\n",
            "          26,  22],\n",
            "        [ 13,  27,  13,   6,  16,  64,  19, 211,   4,   8,   6, 168,   8,   6,\n",
            "          45,  12,  13,  51,  17,   4, 132,   8,   0,   8,   9,   9, 210,   6,\n",
            "          13,   6,  17,  17,  12,  16,  84,  13,  12,  15,   9,  21,  87,  64,\n",
            "         126,  77,   6, 110,  13,   8,  19,  21,  21,   8,  43, 121,   9,  49,\n",
            "           9,   7,   4, 148,   9,   8,  21,   8,  88,   8,  36,   7, 222,  12,\n",
            "           6, 137,  37,  42,   0,  40,  84,   8, 147,  12,  33,   0,  81,  17,\n",
            "         153, 112,  64,  16,   9,  13,  19,   6,  13,  33,  40,  19,   6,  13,\n",
            "          18,  13,   0, 204,  16,  77,   0,  60,  11,  64,  13,   6, 192,   6,\n",
            "           8,  46,  16,  65,  85,  12, 128,  13,   9,  33,   8,  13,  21, 173,\n",
            "          36,   5],\n",
            "        [ 10,   4,  95, 105,   4,  54,  38,   6,   3, 238,  14,   7, 231,   7,\n",
            "           4,   7, 167,   4,   7,   3,   4, 180,   4, 111,  50,   4,   6,   4,\n",
            "          10,   4,   7,   7,   7,   4,   6, 166,   7,   4,   4,   4,   4,  54,\n",
            "           7,  50,   4,   4, 190, 164,  73,   4,   4,   0,   4,   4,   4,   4,\n",
            "           4,   3,   3,   4,   4,   0,   4,   0,  14, 122,  61,   3,   4,   4,\n",
            "           4,   6,  10,   0,   4,   7,   6,   0,   4,   7,   4,   4,   4,   4,\n",
            "           4,   4,  54,   4,   4,   0, 239,   4,  34,   4,   7,  24,   4,  16,\n",
            "           9,  10,   4, 109,   4,  16,   4,   4, 125,  54,  70,   7,   4, 106,\n",
            "          70,   4,   4,  14,   4,   4,  14, 166,   4,   4,   0,  70,   4,   4,\n",
            "          75, 133],\n",
            "        [  7,   3,   4,  14,   3,   4,   4,   4,   1,   4,   3,   3,   4,   3,\n",
            "           3,   3,   4,   3,   3,   1,   3,   4,   3,   4,  14,   3,   4,   3,\n",
            "           7,   3,   3,   3,   3,   3,   7,   4,   3,   3,   3,   3,   3,   4,\n",
            "           3,   4,   3,   3,   4,   4,   4,   3,   3,   4,   3,   3,   3,   3,\n",
            "           3,   1,   1,   3,   3,   4,   3,   4,   3,   4,   4,   1,   3,   3,\n",
            "           3,   4,  14,   4,   3,   3,   4,   4,   3,   3,   3,   3,   3,   3,\n",
            "           3,   3,   4,   3,   3,   0,   4,   3, 129,   3,   3,   4,   3,   4,\n",
            "          14,   7,   3,   4,   3,   4,   3,   3,   4,   4,   4,   3,   3,   4,\n",
            "           4,   3,   3,   3,   3,   3,   3,   4,   3,   3,   4,   4,   3,   3,\n",
            "           4,  14],\n",
            "        [  3,   1,   3,   3,   1,   3,   3,   3,   1,   3,   1,   1,   3,   1,\n",
            "           1,   1,   3,   1,   1,   1,   1,   3,   1,   3,   3,   1,   3,   1,\n",
            "           3,   1,   1,   1,   1,   1,   3,   3,   1,   1,   1,   1,   1,   3,\n",
            "           1,   3,   1,   1,   3,   3,   3,   1,   1,   3,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   3,   1,   3,   1,   3,   3,   1,   1,   1,\n",
            "           1,   3,   3,   3,   1,   1,   3,   3,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   3,   1,   1,   4,   3,   1,   4,   1,   1,   3,   1,   3,\n",
            "           3,   3,   1,   3,   1,   3,   1,   1,   3,   3,   3,   1,   1,   3,\n",
            "           3,   1,   1,   1,   1,   1,   1,   3,   1,   1,   3,   3,   1,   1,\n",
            "           3,   3],\n",
            "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   3,   1,   1,   3,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1]])\n",
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2],\n",
            "        [136,   5,  31, 140,   0,  11,   5, 259,   5, 155,  32,   5, 116,  62,\n",
            "           5,   5,  11,   9,   5,   0,   5,   5, 159,  30,  24,  74,   5,  10,\n",
            "          23,   5,  27, 154,  39,  31,  37,  47,  37,   5,  26,  11,   5,  39,\n",
            "          46,   9,  11, 117, 114,  27, 109,   5,  96,   6,  24,   5,   5,  27,\n",
            "          10,   5,  26,  10,   5,   5,   5,   5,   9, 124,  11,   5,   5,   0,\n",
            "           5,   5,  20,   5,   9,  23,  23,   5,   5,  47,   5,  31, 185,  37,\n",
            "          20,   5,  23,  11,  35,  10,   5,  28,   5,  26,   5,  96,   5,  18,\n",
            "           5,  55,  23,   5,   5,  80,   5,   6,  20, 206,   5,  32,  58,   5,\n",
            "          25,   0,  25,  22,  48, 136,  11, 149,  48, 203,   0, 178, 252,   5,\n",
            "          11,  44],\n",
            "        [ 21,   8,   6,   4,   6,  17,   8,   7,   8,  29,   6,   8,  15,   6,\n",
            "          89,  19,  17,   0,   8,  53,  53,   8,  16,   6,   0,  29,  22,  11,\n",
            "           6,   8,  61,  65,  51,   6,   0,  15,  19,   8,  36,  12,  30,  51,\n",
            "         200, 103,  17,  16,   6,  61,   0,  43,  33,  13,  57,  72, 214,  17,\n",
            "          64,  22,  36,  12,  77,   0,  30,   8,  60,   6,  17,   8,   8,  40,\n",
            "           8,  68,  93, 232,  88,   6,   6, 209, 138,   9,   0,  40,   7,  53,\n",
            "          93, 245,   6,  12,   0,  12, 147,   6,   8,  36,   0,  33,   0, 115,\n",
            "          53,  15,   6,   8, 237,   7,   8,   0, 148,   6, 251,   6,  13,   8,\n",
            "          85,   4,  22,   5,  15,  15,  12,  14,  69,  50,   7,  69,   9, 195,\n",
            "          12,  15],\n",
            "        [  4, 105,   4,   3,   4,   7, 187,   3,   0,   7,   4, 246,   4,   4,\n",
            "         108, 250,   7,   4,  34,   4,   7,  86,   4,  14,   4,   4, 118,   6,\n",
            "           4,  49,   4,   4,   4,   7,  71,   4,  10,  34,  75,   7,  70,   4,\n",
            "           4,   4,   7,   7,   4,   4,   4,   4,   4, 150,   4,  27,   6,   4,\n",
            "          54,  78,  75,   4,  50,   4,   6,  74,   4,   4,   7,   0,  71,   4,\n",
            "         231,   6,   4,   4,   4,   4,   4,   6,   6,   4,   4,   4,   3,   4,\n",
            "           4,   6,   4,   7,  14,   7,   4, 122, 174,  41,   4,   4,   4,   4,\n",
            "           4,   4,   4, 164,   4,   3,  34,  15,   4,   4,   6,   4,  10, 118,\n",
            "          14,   3,   5, 216,   4,   4,   7,   3,   4,   4,   3,   4,   4,  16,\n",
            "           7,   4],\n",
            "        [  3,   4,   3,   1,   3,   3,   4,   1,   4,   3,   3,   4,   3,   3,\n",
            "           4,   4,   3,   3, 156,   3,   3,   7,   3,   3,   3,   3,   4,   4,\n",
            "           3,   4,   3,   3,   3,   3,   4,   3,   4, 212,   4,   3,   4,   3,\n",
            "           3,   3,   3,   3,   3,   3,   3,   3,   3,   4,   3,   4,   4,   3,\n",
            "           4,   4,   4,   3,   4,   3,   4,   4,   3,   3,   3,   4,   4,   3,\n",
            "           4,   4,   3,   3,   3,   3,   3,   4,   4,   3,   3,   3,   1,   3,\n",
            "           3,   4,   3,   3,   3,   3,   3,  14,   4,   4,   3,   3,   3,   3,\n",
            "           3,   3,   3,   4,   3,   1, 156,   4,   3,   3,   4,   3,   7,   4,\n",
            "           3,   1,  14,  14,   3,   3,   3,   1,   3,   3,   1,   3,   3,   4,\n",
            "           3,   3],\n",
            "        [  1,   3,   1,   1,   1,   1,   3,   1,   3,   1,   1,   3,   1,   1,\n",
            "           3,   3,   1,   1,   4,   1,   1,   3,   1,   1,   1,   1,   3,   3,\n",
            "           1,   3,   1,   1,   1,   1,   3,   1,   3,   4,   3,   1,   3,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,   3,   3,   1,\n",
            "           3,   3,   3,   1,   3,   1,   3,   3,   1,   1,   1,   3,   3,   1,\n",
            "           3,   3,   1,   1,   1,   1,   1,   3,   3,   1,   1,   1,   1,   1,\n",
            "           1,   3,   1,   1,   1,   1,   1,   3,   3,   3,   1,   1,   1,   1,\n",
            "           1,   1,   1,   3,   1,   1,   4,   3,   1,   1,   3,   1,   3,   3,\n",
            "           1,   1,   3,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,\n",
            "           1,   1],\n",
            "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   3,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1]])\n",
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2],\n",
            "        [  6,  94, 141, 202, 141,   5,  30,  59,  26,   0,   5,  11, 158,   5,\n",
            "          20,   5,  32,   0, 113,   0,   5,  11,  82,   5,   5,  11, 101,   0,\n",
            "          38,  10,  42,   0,  28,   5,  80,   5,   5,  59,  82,   5,  10,  20,\n",
            "          10,  11,   5,  22,   5,   5,   5,   5,  10,   5,  32,  10,  18,   9,\n",
            "         159, 178,   5,   6,   6, 107, 117,   5,  10,   9, 130,   5,   5,   0,\n",
            "           6,   5,   0, 111,  31,   6,  11,  10, 114,  37,   5,  44,   5, 213,\n",
            "          44,   9,  35,   5, 169,  20,  28,  23,  38,   5,  31,  35,  31, 100,\n",
            "         155,  25,  30,  74,  18,  32,   6,   5,   5,  24,   9,  41,   5,   5,\n",
            "         162, 116,  39,   9,  28,  11,   5,   0,  10,  10,   5,  10,   0,  37,\n",
            "           5,   5],\n",
            "        [ 13,  29,   4,   4,   4,   0,   6,  90,   6,   0,   8,  12, 102, 179,\n",
            "         145,  98,   6,  16,  16,   6,   0,  12,  21,  77,  30,  12,   9,   4,\n",
            "           7,  40,   5,   6,   9,  19,  16,   8,   8,  90,  21, 253,  12, 145,\n",
            "          12,  29,  19,   5,   8, 201,  56,   8,  12, 127,   6,  12,  13,  65,\n",
            "          16,  69,  11,  13, 205,   6,  16,   8,  12,  17,   6, 261,  17,  16,\n",
            "         257,  89,   4,  14,  33,  13,  17,  64,   9,  46,   8,   9,  72,   5,\n",
            "          15, 143, 225,   0,   7, 227,   6,   6,   7, 104,  33, 126, 186,   9,\n",
            "          29,  88,   6, 146,  13,   6, 257, 233, 255,  40, 112,   0,   8,  11,\n",
            "          15,  15,  51,  92,  18,  17,   8,   4,  12,  12,   8,  12,  45,  17,\n",
            "          87, 177],\n",
            "        [165,   4,   3,   3,   3,  17,   7,   7, 106,   4,   0,   7,   4,   4,\n",
            "           4,   4,   4,   7,   4,   4, 109,   7,   4,  50,   6,   7,   4,   3,\n",
            "           3,   4,  10,   4,  71,  62,   4, 111, 171,   7,   4,   4,   7,   4,\n",
            "           4,   4,   0,   0, 142,   4,   9, 135,   7,   6,   4,   7,  34,   4,\n",
            "           4,   4, 125, 196,   4,   4,   4,   0,   7,   4,   7,   4,   6,   7,\n",
            "           4, 142,   3,   3,   4,   0,   7,  54,   4,   4,  83,   4,  69,  10,\n",
            "           4,   4,   7,   4,   3,   4,  70,   4,   3,   9,   4,   7,   4,   4,\n",
            "           7,  14,  14,   7,  78,   4,   4,   4,  10,   4,   4,   4,   0,   6,\n",
            "           4,   4,   4,   4,   9,   7, 217,   3,   7,   4, 170,   4,   7,   4,\n",
            "           9,   4],\n",
            "        [  4,   3,   1,   1,   1,   4,   3,   3,   4,   3,   4,   3,   3,   3,\n",
            "           3,   3,   3,   3,   3,   3,   4,   3,   3,   4,   4,   3,   3,   1,\n",
            "           1,   3,  14,   3,  14,   4,   3,   4,   4,   3,   3,   3,   3,   3,\n",
            "           3,   3,   4,  14,   4,   3,   4,   4,   3,   4,   3,   3, 129,   3,\n",
            "           3,   3,   4,   4,   3,   3,   3,   4,   3,   3,   3,   3,   4,   3,\n",
            "           3,   4,   1,   1,   3,   4,   3,   4,   3,   3,   4,   3,   4,  14,\n",
            "           3,   3,   3,   3,   1,   3,  14,   3,   1,   4,   3,   3,   3,   3,\n",
            "           3,   3,   3,   3,   4,   3,   3,   3,   4,   3,   3,   3,   4,   4,\n",
            "           3,   3,   3,   3,  14,   3,   4,   1,   3,   3,   4,   3,   3,   3,\n",
            "           4,   3],\n",
            "        [  3,   1,   1,   1,   1,   3,   1,   1,   3,   1,   3,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   3,   1,   1,   3,   3,   1,   1,   1,\n",
            "           1,   1,   3,   1,   3,   3,   1,   3,   3,   1,   1,   1,   1,   1,\n",
            "           1,   1,   3,   3,   3,   1,   3,   3,   1,   3,   1,   1,   4,   1,\n",
            "           1,   1,   3,   3,   1,   1,   1,   3,   1,   1,   1,   1,   3,   1,\n",
            "           1,   3,   1,   1,   1,   3,   1,   3,   1,   1,   3,   1,   3,   3,\n",
            "           1,   1,   1,   1,   1,   1,   3,   1,   1,   3,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   3,   1,   1,   1,   3,   1,   1,   1,   3,   3,\n",
            "           1,   1,   1,   1,   3,   1,   3,   1,   1,   1,   3,   1,   1,   1,\n",
            "           3,   1],\n",
            "        [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "           1,   1]])\n",
            "tensor([[  2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
            "           2,   2,   2,   2,   2,   2],\n",
            "        [127,   6,  41,   5,   5,   5, 116,   5,   5, 100,  26,   6,   5, 157,\n",
            "         144,   5,  10,  10,   0,  11,  11,  41,   5,   0,   5,  66,  37, 101,\n",
            "           5,  79,  10,  38,   5,  20,  20,   5,  52,  11,  23,   5,   5, 154,\n",
            "           5,   5,  23,   5,  37, 141,   5,   5, 114,   5,  11,   5,  23,   9,\n",
            "          24,   6,  62,   5,  10, 228,  31, 101,  10,  11,   0,  68,  18,   6,\n",
            "           5,  32, 161,  35,  76,  35,  24,  26,  99, 113,  10,   9, 152,   5,\n",
            "           5,  24,  28, 116,  32,  18,   6,   5,  30,  23,  58,   5,  48, 242,\n",
            "          73,   9,   5, 149,  48,  11],\n",
            "        [  5,  13,   9,  56,   0,  42,  15,   8,   0,   9,  36,  13,  89,   7,\n",
            "           6,   8,  12,  12, 189,  86,  45,   9,  22,  16,   8,  15, 120,   9,\n",
            "           8,  69, 207,  15,  30,  95, 123,  19,  21,  12,   6, 181,  22, 151,\n",
            "           0,   0,   6, 219, 115,  91, 213,   8,   6, 201,  17,  43,   6,  98,\n",
            "         234,  13,   9, 188,  12,   7,  33,   9,  12,   0,  45,  67,  65,  13,\n",
            "          19,  45,  67,   0,  16, 145,  49,   6,   9,  16,  12,  65,   9,   8,\n",
            "          43,  57,   6,  15,  45,  28,  13,   8,   6,   6,  13,  87,  15,   4,\n",
            "           4, 103,   8,  14,   9,  12],\n",
            "        [119,  74,   4,   9,   4,  10,   7,  56,  16,   4,  75, 200, 230,   3,\n",
            "           4, 190,   7,   4,   4,   4,   7,   4, 118,   7, 131,  14,   4,   4,\n",
            "         241,   4,   4,   4,  83,   4,   4,  46,   4,   7,   4,   4, 238,   4,\n",
            "           4,   4,   4,   4,   4,   9, 119, 223,   4,   4,   7,   4,   4,   4,\n",
            "           4,  71,   4,   4,   4,   3,   4,   4,   4,   7,   4,   4,   4, 182,\n",
            "           0,   4,   7,   7,   4,   7,   4,   4,   4,   7,   4,   4,   4, 254,\n",
            "           4,   4,   0,   4,   7, 142,   9, 247,   7,   4,  10,   4,   4,   3,\n",
            "           3,   4,   0,   3,   4,   7],\n",
            "        [ 14,   4,   3,   4,   3,   4,   3,   7,   4,   3,   4,   4,   4,   1,\n",
            "           3,   4,   3,   3,   3,   3,   3,   3,   4,   3,   4,   3,   3,   3,\n",
            "           4,   3,   3,   3,   4,   3,   3,   4,   3,   3,   3,   3,   4,   3,\n",
            "           3,   3,   3,   3,   3,   4,   4,   4,   3,   3,   3,   3,   3,   3,\n",
            "           3,   4,   3,   3,   3,   1,   3,   3,   3,   3,   3,   3,   3,   4,\n",
            "           4,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   4,\n",
            "           3,   3,  14,   3,   3,   4,   4,   4,   3,   3,   7,   3,   3,   1,\n",
            "           1,   3,   4,   1,   3,   3],\n",
            "        [  3,   3,   1,   3,   1,   3,   1,   3,   3,   1,   3,   3,   3,   1,\n",
            "           1,   3,   1,   1,   1,   1,   1,   1,   3,   1,   3,   1,   1,   1,\n",
            "           3,   1,   1,   1,   3,   1,   1,   3,   1,   1,   1,   1,   3,   1,\n",
            "           1,   1,   1,   1,   1,   3,   3,   3,   1,   1,   1,   1,   1,   1,\n",
            "           1,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,\n",
            "           3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   3,\n",
            "           1,   1,   3,   1,   1,   3,   3,   3,   1,   1,   3,   1,   1,   1,\n",
            "           1,   1,   3,   1,   1,   1]])\n",
            "Número de batches: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_seq2seq(\n",
        "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
        "):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(data_loader):\n",
        "        src = batch[\"de_ids\"].to(device)   # device és gpu collab ja que és on fem les probes per no gasta hores de mv azure\n",
        "        trg = batch[\"en_ids\"].to(device)\n",
        "        # src = [src length, batch size]\n",
        "        # trg = [trg length, batch size]\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, teacher_forcing_ratio)\n",
        "        # output = [trg length, batch size, trg vocab size]\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "        trg = trg[1:].view(-1)\n",
        "        # trg = [(trg length - 1) * batch size]\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(data_loader)\n",
        "\n",
        "def evaluate_seq2seq(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            src = batch[\"de_ids\"].to(device)\n",
        "            trg = batch[\"en_ids\"].to(device)\n",
        "            # src = [src length, batch size]\n",
        "            # trg = [trg length, batch size]\n",
        "            output = model(src, trg, 0)  # turn off teacher forcing\n",
        "            # output = [trg length, batch size, trg vocab size]\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
        "            trg = trg[1:].view(-1)\n",
        "            # trg = [(trg length - 1) * batch size]\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "    return epoch_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "u46rz8sOxLHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 2\n",
        "clip = 1.0\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "for epoch in tqdm.tqdm(range(n_epochs)):  #tqdm per veure el processament del bucle, ja que tardará molt\n",
        "    train_loss = train_seq2seq(\n",
        "        model,\n",
        "        train_data_loader,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        clip,\n",
        "        teacher_forcing_ratio,\n",
        "        device,\n",
        "    )\n",
        "    valid_loss = evaluate_seq2seq(\n",
        "        model,\n",
        "        valid_data_loader,\n",
        "        criterion,\n",
        "        device,\n",
        "    )\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), \"tut3-model.pt\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "4Uvt4EQV_wLi",
        "outputId": "7260a1c3-8b3d-43ac-daf6-8376e4db87ee",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2 [00:12<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'valid_data_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-0d8e97ae57af>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     valid_loss = evaluate_seq2seq(\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'valid_data_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0daxG-aBJrl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}